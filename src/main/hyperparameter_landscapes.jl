using Plots
using StaticArrays

function train_validate_test(ğ’Ÿ_train, ğ’Ÿ_validate, ğ’Ÿ_test, problem; log_Î³s=-1.0:0.1:1.0, distances=[euclidean_distance, derivative_distance, antiderivative_distance],descriptor="")
    # Train GP on the filenames in train;
    # Optimize hyperparameter values by testing on filenames in validate;
    # Compute error on the filenames in test.

    nd = length(distances)
    nk = 4
    min_logÎ³s       = zeros(nd,nk)
    validate_errors = zeros(nd,nk)
    test_errors     = zeros(nd,nk)

    for k in 1:nk, (i, d) in enumerate(distances)
        min_logÎ³, min_error_validate, test_error = get_min_gamma(k, d, ğ’Ÿ_train, ğ’Ÿ_validate, ğ’Ÿ_test; log_Î³s=log_Î³s)
        min_logÎ³s[i,k]       = min_logÎ³
        validate_errors[i,k] = min_error_validate
        test_errors[i,k]     = test_error
    end

    # # for rational quadratic kernel, have 2 hyperparameters to optimize
    # k=5
    # for (i, d) in enumerate(distances)
    #     min_logÎ³, min_error_validate, test_error = get_min_gamma_alpha(k, d, ğ’Ÿ_train, ğ’Ÿ_validate, ğ’Ÿ_test; log_Î³s=log_Î³s)
    #     min_logÎ³s[i,5]       = min_logÎ³
    #     validate_errors[i,5] = min_error_validate
    #     test_errors[i,5]     = test_error
    # end

    println("MIN LOG Î³s")
    println(min_logÎ³s)
    println("VALIDATE Mean Error")
    println(validate_errors)
    println("TEST Mean Error")
    println(test_errors)

    a = argmin(test_errors)
    d = a[1]
    k = a[2]
    logÎ³    = min_logÎ³s[d,k]
    kernel  = get_kernel(k, logÎ³, 0.0, distances[d])
    â„³      = model(ğ’Ÿ_train; kernel=kernel)
    anim    = animate_profile_and_model_output(â„³, ğ’Ÿ_test)
    gif(anim, "$(descriptor)_$(typeof(problem))_$(problem.type)_kernel_$(k)_gamma_$(logÎ³).gif");

    println("===============")
    println("-- kernel ............. $(k)")
    println("-- norm ............... $(distances[d])")
    println("-- logÎ³ ............... $(logÎ³)")
    println("-- validate error ..... $(validate_errors[d, k])")
    println("-- test error ......... $(test_errors[d, k])")

    return (min_logÎ³s, validate_errors, test_errors)
end



function get_min_gamma(k, distance, ğ’Ÿ_train, ğ’Ÿ_validate, ğ’Ÿ_test; log_Î³s=-0.3:0.1:0.3)

    errors_validate = zeros(length(log_Î³s))

    for (i, logÎ³) in enumerate(log_Î³s)

        kernel = get_kernel(k, logÎ³, 0.0, distance)
        â„³ = model(ğ’Ÿ_train; kernel=kernel)

        # -----compute mean error for true check----
        errors_validate[i] = get_me_true_check(â„³, ğ’Ÿ_validate)
    end

    i                   = argmin(errors_validate)
    min_logÎ³            = log_Î³s[i]
    min_error_validate  = errors_validate[i]

    # using the log_Î³ value that minimizes the error on the validation set,
    # see how the model performs on the test set.
    kernel = get_kernel(k, min_logÎ³, 0.0, distance)
    â„³ = model(ğ’Ÿ_train; kernel=kernel);
    error_test = get_me_true_check(â„³, ğ’Ÿ_test)

    return (min_logÎ³, min_error_validate, error_test)
end

# function get_min_gamma(k::Int64, ğ’Ÿ::ProfileData, distance, log_Î³s)
#     # returns the gamma value that minimizes the mean error on the true check
#     # - only tests the gamma values listed in the log_Î³s parameter
#
#     mets  = zeros(length(log_Î³s)) # mean error for each gamma (true check)
#     for (i, logÎ³) in enumerate(log_Î³s)
#
#         kernel = get_kernel(k, logÎ³, 0.0, distance)
#         â„³ = model(ğ’Ÿ; kernel=kernel);
#
#         # -----compute mean error for true check----
#         mets[i] = get_me_true_check(â„³, ğ’Ÿ)
#     end
#
#     i = argmin(mets)
#     min_logÎ³ = log_Î³s[i]
#     min_error = mets[i]
#
#     return (min_logÎ³, min_error)
# end

function get_min_gamma_alpha(k, distance, ğ’Ÿ_train, ğ’Ÿ_validate, ğ’Ÿ_test; log_Î³s=-0.3:0.1:0.3, log_Î±s=-0.3:0.1:0.3)
    # returns the gamma value that minimizes the mean error on the true check
    # only tests the gamma values listed in log_Î³s parameter

    errors_validate = @MArray zeros(length(log_Î³s), length(log_Î±s))

    for i in eachindex(log_Î³s), j in eachindex(log_Î±s)

        kernel = get_kernel(k, log_Î³s[i], 0.0, distance; logÎ±=log_Î±s[j])
        â„³ = model(ğ’Ÿ_train; kernel=kernel);

        # -----compute mean error for true check----
        errors_validate[i,j] = get_me_true_check(â„³, ğ’Ÿ_validate)
    end

    m = argmin(errors_validate)
    min_logÎ³ = log_Î³s[m[1]]
    min_logÎ± = log_Î±s[m[2]]
    min_error_validate = errors_validate[m]

    # using the log_Î³ value that minimizes the error on the validation set,
    # see how the model performs on the test set.
    kernel = get_kernel(k, min_logÎ³, 0.0, distance; logÎ±=min_logÎ±)
    â„³ = model(ğ’Ÿ_train; kernel=kernel);
    error_test = get_me_true_check(â„³, ğ’Ÿ_test)

    return (min_logÎ³, min_error_validate, error_test)
end



function plot_landscapes_compare_error_metrics(k::Int64, ğ’Ÿ::ProfileData, distance, log_Î³s)
    # Compare mean log marginal likelihood with
    #    mean error on greedy check and
    #    mean error on true check

    mlls = zeros(length(log_Î³s)) # mean log marginal likelihood
    mes  = zeros(length(log_Î³s)) # mean error (greedy check)
    mets  = zeros(length(log_Î³s)) # mean error (true check)

    for i in 1:length(log_Î³s)

        kernel = get_kernel(k, log_Î³s[i], 0.0, distance)
        â„³ = model(ğ’Ÿ; kernel=kernel)

        # -----compute mll loss----
        mlls[i] = -1*mean_log_marginal_loss(ğ’Ÿ.y_train, â„³, add_constant=false)

        # -----compute mean error for greedy check (same as in plot log error)----
        mes[i] = get_me_greedy_check(â„³, ğ’Ÿ)

        # -----compute mean error for true check----
        mets[i] = get_me_true_check(â„³, ğ’Ÿ)

    end

    ylims = ( minimum([minimum(mets), minimum(mes)]) , maximum([maximum(mets), maximum(mes)]) )

    mll_plot = plot(log_Î³s, mlls, xlabel="log(Î³)", title="negative mean log marginal likelihood, P(y|X)", legend=false, yscale=:log10) # 1D plot: mean log marginal loss vs. Î³
    vline!([log_Î³s[argmin(mlls)]])
    mes_plot  = plot(log_Î³s, mes,  xlabel="log(Î³)", title="ME on greedy check, min = $(round(minimum(mes);digits=7))", legend=false, yscale=:log10, ylims=ylims)  # 1D plot: mean error vs. Î³
    vline!([log_Î³s[argmin(mes)]])
    met_plot  = plot(log_Î³s, mets,  xlabel="log(Î³)", title="ME on true check, min = $(round(minimum(mets);digits=7))", legend=false, yscale=:log10, ylims=ylims)  # 1D plot: mean error vs. Î³
    vline!([log_Î³s[argmin(mets)]])

    layout = @layout [a; b; c]
    return plot(mll_plot, mes_plot, met_plot, layout = layout)
end


function plot_landscapes_compare_files_me(filenames, k::Int64, distance, log_Î³s, problem; D=16, N=4)
    # visual comparison of the mean error on true check for every file in filenames

    function get_me(filename)
        ğ’Ÿ = data(file, problem; D=D, N=N)

        mes  = zeros(length(log_Î³s))
        for i in 1:length(log_Î³s)
            kernel = get_kernel(k, log_Î³s[i], 0.0, distance)
            â„³ = model(ğ’Ÿ; kernel=kernel)
            mes[i] = get_me_true_check(â„³, ğ’Ÿ)
        end

        return mes
    end

    results = Dict(file => get_me(file) for file in filenames)

    # put all the data into one array for plotting
    for r in results
        all = hcat(all, r[file])
    end

    layout = (length(filenames), 1)
    ylims = (minimum(all),maximum(all))

    # minimizing Î³ values
    argmin_logÎ³ = vcat([log_Î³s[argmin(results[file])]
                for file in filenames])

    titles = ["$(file), log(Î³)=$(argmin_logÎ³[i]), min = $(round(minimum(results[filenames[i]]);digits=5))"
             for i in eachindex(filenames)]

    p = plot(log_Î³s, xlabel="log(Î³)", ylabel="ME, true check", title=titles, legend=false, yscale=:log10, ylims=ylims, layout=layout)  # 1D plot: mean error vs. Î³

    vline!(argmin_Î³')

    return p
end

function plot_error_histogram(â„³, ğ’Ÿ::ProfileData, time_index)
    # mean error for true check
    gpr_prediction = predict(â„³, ğ’Ÿ; postprocessed=true)
    n = ğ’Ÿ.Nt-1

    gpr_error = zeros(n-1)
    for i in 1:n-1
        exact    = ğ’Ÿ.vavg[i+1]
        predi    = gpr_prediction[i+1]
        gpr_error[i] = euclidean_distance(exact, predi) # euclidean distance
    end
    mean_error = sum(gpr_error) / n

    error_plot_log = histogram(log.(gpr_error), title = "log(error) at each timestep of the full evolution", xlabel="log(Error)", ylabel="Frequency",ylims=(0,250), label="frequency")
    vline!([log(mean_error)], line = (4, :dash, 0.8), label="mean error")
    vline!([log(gpr_error[time_index])], line = (1, :solid, 0.6), label="error at t=$(time_index)")
end
