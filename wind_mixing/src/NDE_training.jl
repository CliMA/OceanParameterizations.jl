using Flux
using OceanParameterizations
using Oceananigans.Grids
using BSON
using OrdinaryDiffEq, DiffEqSensitivity
using GalacticOptim

include("data_containers.jl")

function predict_NDE(NN, x, top, bottom)
    interior = NN(x)
    return [top; interior; bottom]
end

function time_window(t, uvT, trange)
    return (Float32.(t[trange]), Float32.(uvT[:,trange]))
end

function save_NDE_weights(weights, size_uw_NN, size_vw_NN, size_wT_NN, FILE_PATH, filename)
    uw_weights = weights[1:size_uw_NN]
    vw_weights = weights[size_uw_NN + 1:size_uw_NN + size_vw_NN]
    wT_weights = weights[size_uw_NN + size_vw_NN + 1:size_uw_NN + size_vw_NN + size_wT_NN]
    uw_NN_params = Dict(:weights => uw_weights)
    bson(joinpath(FILE_PATH, "uw_$filename.bson"), uw_NN_params)

    vw_NN_params = Dict(:weights => vw_weights)
    bson(joinpath(FILE_PATH, "vw_$filename.bson"), vw_NN_params)

    wT_NN_params = Dict(:weights => wT_weights)
    bson(joinpath(FILE_PATH, "wT_$filename.bson"), wT_NN_params)
end

function cb(args...)
    @info "loss = $(args[2])"
    false
end

function train_NDE(uw_NN, vw_NN, wT_NN, ğ’Ÿtrain, tsteps, timestepper, optimizers, epochs, OUTPUT_PATH, filename)
    f = 1f-4
    H = Float32(abs(ğ’Ÿtrain.uw.z[end] - ğ’Ÿtrain.uw.z[1]))
    Ï„ = Float32(abs(ğ’Ÿtrain.t[:,1][end] - ğ’Ÿtrain.t[:,1][1]))
    Nz = 32
    u_scaling = ğ’Ÿtrain.scalings["u"]
    v_scaling = ğ’Ÿtrain.scalings["v"]
    T_scaling = ğ’Ÿtrain.scalings["T"]
    uw_scaling = ğ’Ÿtrain.scalings["uw"]
    vw_scaling = ğ’Ÿtrain.scalings["vw"]
    wT_scaling = ğ’Ÿtrain.scalings["wT"]
    Î¼_u = Float32(u_scaling.Î¼)
    Î¼_v = Float32(v_scaling.Î¼)
    Ïƒ_u = Float32(u_scaling.Ïƒ)
    Ïƒ_v = Float32(v_scaling.Ïƒ)
    Ïƒ_T = Float32(T_scaling.Ïƒ)
    Ïƒ_uw = Float32(uw_scaling.Ïƒ)
    Ïƒ_vw = Float32(vw_scaling.Ïƒ)
    Ïƒ_wT = Float32(wT_scaling.Ïƒ)
    uw_weights, re_uw = Flux.destructure(uw_NN)
    vw_weights, re_vw = Flux.destructure(vw_NN)
    wT_weights, re_wT = Flux.destructure(wT_NN)
    uw_top = Float32(ğ’Ÿtrain.uw.scaled[1,1])
    uw_bottom = Float32(ğ’Ÿtrain.uw.scaled[end,1])
    vw_top = Float32(ğ’Ÿtrain.vw.scaled[1,1])
    vw_bottom = Float32(ğ’Ÿtrain.vw.scaled[end,1])
    wT_top = Float32(ğ’Ÿtrain.wT.scaled[1,1])
    wT_bottom = Float32(ğ’Ÿtrain.wT.scaled[end,1])

    D_cell = Float32.(Dá¶œ(Nz, 1/Nz))

    size_uw_NN = length(uw_weights)
    size_vw_NN = length(vw_weights)
    size_wT_NN = length(wT_weights)
    weights = Float32[uw_weights; vw_weights; wT_weights]

    function NDE!(dx, x, p, t)
        uw_weights = p[1:size_uw_NN]
        vw_weights = p[size_uw_NN + 1:size_uw_NN + size_vw_NN]
        wT_weights = p[size_uw_NN + size_vw_NN + 1:size_uw_NN + size_vw_NN + size_wT_NN]
        uw_NN = re_uw(uw_weights)
        vw_NN = re_vw(vw_weights)
        wT_NN = re_wT(wT_weights)
        A = - Ï„ / H
        B = f * Ï„
        u = x[1:Nz]
        v = x[Nz+1:2*Nz]
        T = x[2*Nz+1:96]
        dx[1:Nz] .= A .* Ïƒ_uw ./ Ïƒ_u .* D_cell * predict_NDE(uw_NN, x, uw_top, uw_bottom) .+ B ./ Ïƒ_u .* (Ïƒ_v .* v .+ Î¼_v) #nondimensional gradient
        dx[Nz+1:2Nz] .= A .* Ïƒ_vw ./ Ïƒ_v .* D_cell * predict_NDE(vw_NN, x, vw_top, vw_bottom) .- B ./ Ïƒ_v .* (Ïƒ_u .* u .+ Î¼_u)
        dx[2Nz+1:3Nz] .= A .* Ïƒ_wT ./ Ïƒ_T .* D_cell * predict_NDE(wT_NN, x, wT_top, wT_bottom)
    end

    uvTâ‚€ = Float32.(ğ’Ÿtrain.uvT_scaled[:,tsteps[1]])
    t_train, uvT_train = time_window(ğ’Ÿtrain.t, ğ’Ÿtrain.uvT_scaled, tsteps)
    t_train = Float32.(t_train ./ Ï„)
    tspan_train = (t_train[1], t_train[end])

    prob_NDE = ODEProblem(NDE!, uvTâ‚€, tspan_train, weights, saveat=t_train)

    function loss(weights, p)
        sol = Float32.(Array(solve(prob_NDE, timestepper, p=weights, sensealg=InterpolatingAdjoint())))
        return Flux.mse(sol, uvT_train)
    end

    f_loss = OptimizationFunction(loss, GalacticOptim.AutoZygote())
    prob_loss = OptimizationProblem(f_loss, weights)

    for opt in optimizers, epoch in 1:epochs
        @info "Epoch $epoch, $opt"
        res = solve(prob_loss, opt, cb=cb, maxiters = 500)
        weights .= res.minimizer
        save_NDE_weights(weights, size_uw_NN, size_vw_NN, size_wT_NN, OUTPUT_PATH, filename)
    end
    save_NDE_weights(weights, size_uw_NN, size_vw_NN, size_wT_NN, OUTPUT_PATH, filename)
end

function train_NDE_convective_adjustment(uw_NN, vw_NN, wT_NN, ğ’Ÿtrain, tsteps, timestepper, optimizers, epochs, OUTPUT_PATH, filename)
    f = 1f-4
    H = Float32(abs(ğ’Ÿtrain.uw.z[end] - ğ’Ÿtrain.uw.z[1]))
    Ï„ = Float32(abs(ğ’Ÿtrain.t[:,1][end] - ğ’Ÿtrain.t[:,1][1]))
    Nz = 32
    u_scaling = ğ’Ÿtrain.scalings["u"]
    v_scaling = ğ’Ÿtrain.scalings["v"]
    T_scaling = ğ’Ÿtrain.scalings["T"]
    uw_scaling = ğ’Ÿtrain.scalings["uw"]
    vw_scaling = ğ’Ÿtrain.scalings["vw"]
    wT_scaling = ğ’Ÿtrain.scalings["wT"]
    Î¼_u = Float32(u_scaling.Î¼)
    Î¼_v = Float32(v_scaling.Î¼)
    Ïƒ_u = Float32(u_scaling.Ïƒ)
    Ïƒ_v = Float32(v_scaling.Ïƒ)
    Ïƒ_T = Float32(T_scaling.Ïƒ)
    Ïƒ_uw = Float32(uw_scaling.Ïƒ)
    Ïƒ_vw = Float32(vw_scaling.Ïƒ)
    Ïƒ_wT = Float32(wT_scaling.Ïƒ)
    uw_weights, re_uw = Flux.destructure(uw_NN)
    vw_weights, re_vw = Flux.destructure(vw_NN)
    wT_weights, re_wT = Flux.destructure(wT_NN)
    uw_top = Float32(ğ’Ÿtrain.uw.scaled[1,1])
    uw_bottom = Float32(ğ’Ÿtrain.uw.scaled[end,1])
    vw_top = Float32(ğ’Ÿtrain.vw.scaled[1,1])
    vw_bottom = Float32(ğ’Ÿtrain.vw.scaled[end,1])
    wT_top = Float32(ğ’Ÿtrain.wT.scaled[1,1])
    wT_bottom = Float32(ğ’Ÿtrain.wT.scaled[end,1])

    Îº = 10f0

    D_cell = Float32.(Dá¶œ(Nz, 1/Nz))
    D_face = Float32.(Dá¶ (Nz, 1/Nz))

    size_uw_NN = length(uw_weights)
    size_vw_NN = length(vw_weights)
    size_wT_NN = length(wT_weights)
    weights = Float32[uw_weights; vw_weights; wT_weights]

    function predict_NDE(NN, x, top, bottom)
        interior = NN(x)
        return [top; interior; bottom]
    end

    function predict_NDE_convective_adjustment(NN, x, top, bottom)
        interior = NN(x)
        T = @view x[2Nz + 1:3Nz]
        wT = [top; interior; bottom]
        âˆ‚Tâˆ‚z = D_face * T
        âˆ‚z_Îºâˆ‚Tâˆ‚z = D_cell * min.(0f0, Îº .* âˆ‚Tâˆ‚z)
        return - D_cell * wT .+ âˆ‚z_Îºâˆ‚Tâˆ‚z
    end    

    function NDE!(dx, x, p, t)
        uw_weights = p[1:size_uw_NN]
        vw_weights = p[size_uw_NN + 1:size_uw_NN + size_vw_NN]
        wT_weights = p[size_uw_NN + size_vw_NN + 1:size_uw_NN + size_vw_NN + size_wT_NN]
        uw_NN = re_uw(uw_weights)
        vw_NN = re_vw(vw_weights)
        wT_NN = re_wT(wT_weights)
        A = - Ï„ / H
        B = f * Ï„
        u = x[1:Nz]
        v = x[Nz+1:2*Nz]
        T = x[2*Nz+1:96]
        dx[1:Nz] .= A .* Ïƒ_uw ./ Ïƒ_u .* D_cell * predict_NDE(uw_NN, x, uw_top, uw_bottom) .+ B ./ Ïƒ_u .* (Ïƒ_v .* v .+ Î¼_v) #nondimensional gradient
        dx[Nz+1:2Nz] .= A .* Ïƒ_vw ./ Ïƒ_v .* D_cell * predict_NDE(vw_NN, x, vw_top, vw_bottom) .- B ./ Ïƒ_v .* (Ïƒ_u .* u .+ Î¼_u)
        dx[2Nz+1:3Nz] .= -A .* Ïƒ_wT ./ Ïƒ_T .* predict_NDE_convective_adjustment(wT_NN, x, wT_top, wT_bottom)
    end

    uvTâ‚€ = Float32.(ğ’Ÿtrain.uvT_scaled[:,tsteps[1]])
    t_train, uvT_train = time_window(ğ’Ÿtrain.t, ğ’Ÿtrain.uvT_scaled, tsteps)
    t_train = Float32.(t_train ./ Ï„)
    tspan_train = (t_train[1], t_train[end])

    prob_NDE = ODEProblem(NDE!, uvTâ‚€, tspan_train, weights, saveat=t_train)

    function loss(weights, p)
        sol = Array(solve(prob_NDE, timestepper, p=weights, sensealg=InterpolatingAdjoint()))
        return Flux.mse(sol, uvT_train)
    end

    f_loss = OptimizationFunction(loss, GalacticOptim.AutoZygote())
    prob_loss = OptimizationProblem(f_loss, weights)

    for opt in optimizers, epoch in 1:epochs
        @info "Epoch $epoch, $opt"
        res = solve(prob_loss, opt, cb=cb, maxiters=500)
        weights .= res.minimizer
        save_NDE_weights(weights, size_uw_NN, size_vw_NN, size_wT_NN, OUTPUT_PATH, filename)
    end
    save_NDE_weights(weights, size_uw_NN, size_vw_NN, size_wT_NN, OUTPUT_PATH, filename)
end

