
function prepare_parameters_NDE_training(uw_NN, vw_NN, wT_NN, Nz)
    uw_weights, re_uw = Flux.destructure(uw_NN)
    vw_weights, re_vw = Flux.destructure(vw_NN)
    wT_weights, re_wT = Flux.destructure(wT_NN)

    size_uw_NN = length(uw_weights)
    size_vw_NN = length(vw_weights)
    size_wT_NN = length(wT_weights)

    uw_range = 1:size_uw_NN
    vw_range = size_uw_NN + 1:size_uw_NN + size_vw_NN
    wT_range = size_uw_NN + size_vw_NN + 1:size_uw_NN + size_vw_NN + size_wT_NN

    derivatives = (cell=Float32.(Dá¶œ(Nz, 1 / Nz)), face=Float32.(Dá¶ (Nz, 1 / Nz)))
    NN_constructions = (uw=re_uw, vw=re_vw, wT=re_wT)
    weights = Float32[uw_weights; vw_weights; wT_weights]

    NN_ranges = (uw=uw_range, vw=vw_range, wT=wT_range)

    return derivatives, NN_constructions, weights, NN_ranges
end

function prepare_parameters_NDE_training(ğ’Ÿtrain, uw_NN, vw_NN, wT_NN, f, Nz, g, Î±, Î½â‚€, Î½â‚‹, Riá¶œ, Î”Ri, Pr, Îº, conditions)
    H = abs(ğ’Ÿtrain.uw.z[end] - ğ’Ÿtrain.uw.z[1])
    Ï„ = abs(ğ’Ÿtrain.t[:,1][end] - ğ’Ÿtrain.t[:,1][1])
    u_scaling = ğ’Ÿtrain.scalings["u"]
    v_scaling = ğ’Ÿtrain.scalings["v"]
    T_scaling = ğ’Ÿtrain.scalings["T"]
    uw_scaling = ğ’Ÿtrain.scalings["uw"]
    vw_scaling = ğ’Ÿtrain.scalings["vw"]
    wT_scaling = ğ’Ÿtrain.scalings["wT"]

    uw_weights, re_uw = Flux.destructure(uw_NN)
    vw_weights, re_vw = Flux.destructure(vw_NN)
    wT_weights, re_wT = Flux.destructure(wT_NN)

    size_uw_NN = length(uw_weights)
    size_vw_NN = length(vw_weights)
    size_wT_NN = length(wT_weights)

    uw_range = 1:size_uw_NN
    vw_range = size_uw_NN + 1:size_uw_NN + size_vw_NN
    wT_range = size_uw_NN + size_vw_NN + 1:size_uw_NN + size_vw_NN + size_wT_NN

    if conditions.modified_pacanowski_philander
        if conditions.convective_adjustment
            constants = (H=H, Ï„=Ï„, f=f, Nz=Nz, g=g, Î±=Î±, Î½â‚€=Î½â‚€, Î½â‚‹=Î½â‚‹, Riá¶œ=Riá¶œ, Î”Ri=Î”Ri, Pr=Pr, Îº=Îº)
        else
            constants = (H=H, Ï„=Ï„, f=f, Nz=Nz, g=g, Î±=Î±, Î½â‚€=Î½â‚€, Î½â‚‹=Î½â‚‹, Riá¶œ=Riá¶œ, Î”Ri=Î”Ri, Pr=Pr)
        end
    elseif conditions.convective_adjustment
        constants = (H=H, Ï„=Ï„, f=f, Nz=Nz, g=g, Î±=Î±, Îº=Îº)
    else
        constants = (H=H, Ï„=Ï„, f=f, Nz=Nz, g=g, Î±=Î±)
    end
    scalings = (u=u_scaling, v=v_scaling, T=T_scaling, uw=uw_scaling, vw=vw_scaling, wT=wT_scaling)
    derivatives = (cell=Float32.(Dá¶œ(Nz, 1 / Nz)), face=Float32.(Dá¶ (Nz, 1 / Nz)))
    NN_constructions = (uw=re_uw, vw=re_vw, wT=re_wT)
    weights = Float32[uw_weights; vw_weights; wT_weights]

    NN_sizes = (uw=size_uw_NN, vw=size_vw_NN, wT=size_wT_NN)
    NN_ranges = (uw=uw_range, vw=vw_range, wT=wT_range)

    filters = (cell=WindMixing.smoothing_filter(Nz, 3), face=WindMixing.smoothing_filter(Nz+1, 3), interior=WindMixing.smoothing_filter(Nz-1, 3))
    return constants, scalings, derivatives, NN_constructions, weights, NN_sizes, NN_ranges, filters
end

function local_richardson(âˆ‚uâˆ‚z, âˆ‚vâˆ‚z, âˆ‚Tâˆ‚z, H, g, Î±, Ïƒ_u, Ïƒ_v, Ïƒ_T)
    # H, g, Î± = constants.H, constants.g, constants.Î±
    # Ïƒ_u, Ïƒ_v, Ïƒ_T = scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ
    Bz = H * g * Î± * Ïƒ_T * âˆ‚Tâˆ‚z
    SÂ² = (Ïƒ_u * âˆ‚uâˆ‚z) ^2 + (Ïƒ_v * âˆ‚vâˆ‚z) ^2
    return Bz / SÂ²
end

tanh_step(x) = (1 - tanh(x)) / 2

function NDE(x, p, t, dataset, NN_ranges, NN_constructions, conditions, derivatives, diffusivity_scheme)
    uw_range, vw_range, wT_range = NN_ranges.uw, NN_ranges.vw, NN_ranges.wT
    uw_weights, vw_weights, wT_weights = p[uw_range], p[vw_range], p[wT_range]

    uw_bottom, uw_top, vw_bottom, vw_top, wT_bottom, wT_top = p[wT_range[end] + 1:end]
    BCs = (uw=(top=uw_top, bottom=uw_bottom), vw=(top=vw_top, bottom=vw_bottom), wT=(top=wT_top, bottom=wT_bottom))

    re_uw, re_vw, re_wT = NN_constructions.uw, NN_constructions.vw, NN_constructions.wT
    uw_NN = re_uw(uw_weights)
    vw_NN = re_vw(vw_weights)
    wT_NN = re_wT(wT_weights)
    return predict_NDE(uw_NN, vw_NN, wT_NN, x, dataset, BCs, conditions, derivatives, diffusivity_scheme)
end

function NDE(x, p, t, NN_ranges, NN_constructions, conditions, scalings, constants, derivatives, filters)
    uw_range, vw_range, wT_range = NN_ranges.uw, NN_ranges.vw, NN_ranges.wT
    uw_weights, vw_weights, wT_weights = p[uw_range], p[vw_range], p[wT_range]
    uw_bottom, uw_top, vw_bottom, vw_top, wT_bottom, wT_top = p[wT_range[end] + 1:end]
    BCs = (uw=(top=uw_top, bottom=uw_bottom), vw=(top=vw_top, bottom=vw_bottom), wT=(top=wT_top, bottom=wT_bottom))
    re_uw, re_vw, re_wT = NN_constructions.uw, NN_constructions.vw, NN_constructions.wT
    uw_NN = re_uw(uw_weights)
    vw_NN = re_vw(vw_weights)
    wT_NN = re_wT(wT_weights)
    return predict_NDE(uw_NN, vw_NN, wT_NN, x, BCs, conditions, scalings, constants, derivatives, filters)
end

function NDE(x, p, t, NN_ranges, NN_constructions, conditions, scalings, constants, derivatives, filters, wT_top_function)
    uw_range, vw_range, wT_range = NN_ranges.uw, NN_ranges.vw, NN_ranges.wT
    uw_weights, vw_weights, wT_weights = p[uw_range], p[vw_range], p[wT_range]

    uw_bottom, uw_top, vw_bottom, vw_top, wT_bottom = p[wT_range[end] + 1:end-1]
    wT_top = scalings.wT(wT_top_function(t * constants.Ï„))
    
    BCs = (uw=(top=uw_top, bottom=uw_bottom), vw=(top=vw_top, bottom=vw_bottom), wT=(top=wT_top, bottom=wT_bottom))
    re_uw, re_vw, re_wT = NN_constructions.uw, NN_constructions.vw, NN_constructions.wT
    uw_NN = re_uw(uw_weights)
    vw_NN = re_vw(vw_weights)
    wT_NN = re_wT(wT_weights)
    return predict_NDE(uw_NN, vw_NN, wT_NN, x, BCs, conditions, scalings, constants, derivatives, filters)
end

abstract type AbstractBaseDiffusivity end
struct RiBasedDiffusivity{T} <: AbstractBaseDiffusivity
    Î½â‚€::T
    Î½â‚‹::T
    Î”Ri::T
    Riá¶œ::T
    Pr::T
end

function calculate_diffusive_flux(scheme::RiBasedDiffusivity, x, dataset, derivatives)
    Nz = dataset["u"].grid.Nz
    u = @view x[1:Nz]
    v = @view x[Nz + 1:2Nz]
    T = @view x[2Nz + 1:3Nz]

    H = dataset["u"].grid.Lz
    g = dataset.metadata["gravitational_acceleration"]
    Î± = dataset.metadata["thermal_expansion_coefficient"]

    scalings = dataset.metadata["scalings"]

    Ïƒ_u, Ïƒ_v, Ïƒ_T = scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ
    Ïƒ_uw, Ïƒ_vw, Ïƒ_wT = scalings.uw.Ïƒ, scalings.vw.Ïƒ, scalings.wT.Ïƒ

    D_face = derivatives.face

    âˆ‚uâˆ‚z = D_face * u
    âˆ‚vâˆ‚z = D_face * v
    âˆ‚Tâˆ‚z = D_face * T

    Ïµ = 1f-7
    Ri = local_richardson.(âˆ‚uâˆ‚z .+ Ïµ, âˆ‚vâˆ‚z .+ Ïµ, âˆ‚Tâˆ‚z .+ Ïµ, H, g, Î±, Ïƒ_u, Ïƒ_v, Ïƒ_T)

    Î½_velocities = scheme.Î½â‚€ .+ scheme.Î½â‚‹ .* tanh_step.((Ri .- scheme.Riá¶œ) ./ scheme.Î”Ri)
    Î½_T = Î½_velocities ./ scheme.Pr

    Î½âˆ‚uâˆ‚z = Ïƒ_u / Ïƒ_uw / H .* Î½_velocities .* âˆ‚uâˆ‚z
    Î½âˆ‚vâˆ‚z = Ïƒ_v / Ïƒ_vw / H .* Î½_velocities .* âˆ‚vâˆ‚z
    Î½âˆ‚Tâˆ‚z = Ïƒ_T / Ïƒ_wT / H .* Î½_T .* âˆ‚Tâˆ‚z

    return Î½âˆ‚uâˆ‚z, Î½âˆ‚vâˆ‚z, Î½âˆ‚Tâˆ‚z
end

struct ConvectiveAdjustment{T} <: AbstractBaseDiffusivity
    Îº::T
end

function calculate_diffusive_flux(scheme::ConvectiveAdjustment, x, dataset, derivatives)
    Nz = dataset["u"].grid.Nz

    T = @view x[2Nz + 1:3Nz]

    H = dataset["u"].grid.Lz

    âˆ‚Tâˆ‚z = derivatives.face * T

    scalings = dataset.metadata["scalings"]

    Î½âˆ‚uâˆ‚z = zeros(Float32, Nz+1)
    Î½âˆ‚vâˆ‚z = zeros(Float32, Nz+1)
    Î½âˆ‚Tâˆ‚z = scalings.T.Ïƒ / scalings.wT.Ïƒ / H .* scheme.Îº .* min.(0f0, âˆ‚Tâˆ‚z)

    return Î½âˆ‚uâˆ‚z, Î½âˆ‚vâˆ‚z, Î½âˆ‚Tâˆ‚z
end

struct NoDiffusivity <: AbstractBaseDiffusivity
end

function calculate_diffusive_flux(scheme::NoDiffusivity, x, dataset, derivatives)
    Nz = dataset["u"].grid.Nz

    return zeros(Float32, Nz+1), zeros(Float32, Nz+1), zeros(Float32, Nz+1)
end

(scheme::AbstractBaseDiffusivity)(x, dataset, derivatives) = calculate_diffusive_flux(scheme, x, dataset, derivatives)

function predict_flux(uw_NN, vw_NN, wT_NN, x, dataset, BCs, conditions, derivatives, diffusivity_scheme)
    H = dataset["u"].grid.Lz

    scalings = dataset.metadata["scalings"]
    
    uw_scaling, vw_scaling, wT_scaling = scalings.uw, scalings.vw, scalings.wT
    Ïƒ_uw, Ïƒ_vw, Ïƒ_wT = uw_scaling.Ïƒ, vw_scaling.Ïƒ, wT_scaling.Ïƒ
    Ïƒ_u, Ïƒ_v, Ïƒ_T = scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ
    
    Î½âˆ‚uâˆ‚z, Î½âˆ‚vâˆ‚z, Î½âˆ‚Tâˆ‚z = diffusivity_scheme(x, dataset, derivatives)

    uw_interior = uw_NN(x)
    vw_interior = vw_NN(x)
    wT_interior = wT_NN(x)
    
    if conditions.zero_weights
        uw = [0f0; uw_interior; 0f0]
        vw = [0f0; vw_interior; 0f0]
        wT = [0f0; wT_interior; 0f0]

        Î½âˆ‚uâˆ‚z = [-(BCs.uw.bottom - scalings.uw(0f0)); Î½âˆ‚uâˆ‚z[2:end-1]; -(BCs.uw.top - scalings.uw(0f0))]
        Î½âˆ‚vâˆ‚z = [-(BCs.vw.bottom - scalings.vw(0f0)); Î½âˆ‚vâˆ‚z[2:end-1]; -(BCs.vw.top - scalings.vw(0f0))]
        Î½âˆ‚Tâˆ‚z = [-(BCs.wT.bottom - scalings.wT(0f0)); Î½âˆ‚Tâˆ‚z[2:end-1]; -(BCs.wT.top - scalings.wT(0f0))]
    else
        uw = [BCs.uw.bottom; uw_interior; BCs.uw.top]
        vw = [BCs.vw.bottom; vw_interior; BCs.vw.top]
        wT = [BCs.wT.bottom; wT_interior; BCs.wT.top]
    end

    return uw .- Î½âˆ‚uâˆ‚z, vw .- Î½âˆ‚vâˆ‚z, wT .- Î½âˆ‚Tâˆ‚z
end

function predict_flux(uw_NN, vw_NN, wT_NN, x, BCs, conditions, scalings, constants, derivatives, filters)
    Nz, H, Ï„, f = constants.Nz, constants.H, constants.Ï„, constants.f
    uw_scaling, vw_scaling, wT_scaling = scalings.uw, scalings.vw, scalings.wT
    Ïƒ_uw, Ïƒ_vw, Ïƒ_wT = uw_scaling.Ïƒ, vw_scaling.Ïƒ, wT_scaling.Ïƒ
    Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T = scalings.u.Î¼, scalings.v.Î¼, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ
    D_cell, D_face = derivatives.cell, derivatives.face

    u = @view x[1:Nz]
    v = @view x[Nz + 1:2Nz]
    T = @view x[2Nz + 1:3Nz]

    uw_interior = uw_NN(x)
    vw_interior = vw_NN(x)
    wT_interior = wT_NN(x)

    if conditions.smooth_NN
        uw_interior = filters.interior * uw_interior
        vw_interior = filters.interior * vw_interior
        wT_interior = filters.interior * wT_interior
    end
    
    if conditions.zero_weights
        uw = [0f0; uw_interior; 0f0]
        vw = [0f0; vw_interior; 0f0]
        wT = [0f0; wT_interior; 0f0]
    else
        uw = [BCs.uw.bottom; uw_interior; BCs.uw.top]
        vw = [BCs.vw.bottom; vw_interior; BCs.vw.top]
        wT = [BCs.wT.bottom; wT_interior; BCs.wT.top]
    end

    if conditions.modified_pacanowski_philander
        Ïµ = 1f-7
        âˆ‚uâˆ‚z = D_face * u
        âˆ‚vâˆ‚z = D_face * v
        âˆ‚Tâˆ‚z = D_face * T
        Ri = local_richardson.(âˆ‚uâˆ‚z .+ Ïµ, âˆ‚vâˆ‚z .+ Ïµ, âˆ‚Tâˆ‚z .+ Ïµ, constants.H, constants.g, constants.Î±, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ)

        if conditions.smooth_Ri
            Ri = filters.face * Ri
        end

        Î½ = constants.Î½â‚€ .+ constants.Î½â‚‹ .* tanh_step.((Ri .- constants.Riá¶œ) ./ constants.Î”Ri)
        # Î½ = constants.Î½â‚€ .+ constants.Î½â‚‹ .* tanh_step.((Ri .- constants.Riá¶œ) ./ constants.Î”Ri) .+ 1f0 .* tanh_step.((Ri .+ constants.Riá¶œ) ./ constants.Î”Ri)


        if conditions.zero_weights
            Î½âˆ‚uâˆ‚z = [-(BCs.uw.bottom - scalings.uw(0f0)); Ïƒ_u / Ïƒ_uw / H .* Î½[2:end-1] .* âˆ‚uâˆ‚z[2:end-1]; -(BCs.uw.top - scalings.uw(0f0))]
            Î½âˆ‚vâˆ‚z = [-(BCs.vw.bottom - scalings.vw(0f0)); Ïƒ_v / Ïƒ_vw / H .* Î½[2:end-1] .* âˆ‚vâˆ‚z[2:end-1]; -(BCs.vw.top - scalings.vw(0f0))]
            Î½âˆ‚Tâˆ‚z = [-(BCs.wT.bottom - scalings.wT(0f0)); Ïƒ_T / Ïƒ_wT / H .* Î½[2:end-1] ./ constants.Pr .* âˆ‚Tâˆ‚z[2:end-1]; -(BCs.wT.top - scalings.wT(0f0))]
        else
            Î½âˆ‚uâˆ‚z = Ïƒ_u / Ïƒ_uw / H .* Î½ .* âˆ‚uâˆ‚z
            Î½âˆ‚vâˆ‚z = Ïƒ_v / Ïƒ_vw / H .* Î½ .* âˆ‚vâˆ‚z
            Î½âˆ‚Tâˆ‚z = Ïƒ_T / Ïƒ_wT / H .* Î½ .* âˆ‚Tâˆ‚z ./ constants.Pr
        end

        return uw .- Î½âˆ‚uâˆ‚z, vw .- Î½âˆ‚vâˆ‚z, wT .- Î½âˆ‚Tâˆ‚z
    elseif conditions.convective_adjustment
        âˆ‚Tâˆ‚z = D_face * T
        Îºâˆ‚Tâˆ‚z = Ïƒ_T / Ïƒ_wT / H .* Îº .* min.(0f0, âˆ‚Tâˆ‚z)
        return uw, vw, wT .- Îºâˆ‚Tâˆ‚z
    else
        return uw, vw, wT
    end
end

function predict_NDE(uw_NN, vw_NN, wT_NN, x, dataset, BCs, conditions, derivatives, diffusivity_scheme)
    Nz = Int64(dataset["u"].grid.Nz)
    H = dataset["u"].grid.Lz
    Ï„ = dataset.metadata["Ï„"]
    f = dataset.metadata["coriolis_parameter"]

    @assert H > 0 && H isa Float32

    scalings = dataset.metadata["scalings"]

    Ïƒ_uw, Ïƒ_vw, Ïƒ_wT = scalings.uw.Ïƒ, scalings.vw.Ïƒ, scalings.wT.Ïƒ
    Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T = scalings.u.Î¼, scalings.v.Î¼, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ

    u = @view x[1:Nz]
    v = @view x[Nz + 1:2Nz]

    uw, vw, wT = predict_flux(uw_NN, vw_NN, wT_NN, x, dataset, BCs, conditions, derivatives, diffusivity_scheme)
    
    âˆ‚uâˆ‚t = -Ï„ / H * Ïƒ_uw / Ïƒ_u .* derivatives.cell * uw .+ f * Ï„ / Ïƒ_u .* (Ïƒ_v .* v .+ Î¼_v)
    âˆ‚vâˆ‚t = -Ï„ / H * Ïƒ_vw / Ïƒ_v .* derivatives.cell * vw .- f * Ï„ / Ïƒ_v .* (Ïƒ_u .* u .+ Î¼_u)
    âˆ‚Tâˆ‚t = -Ï„ / H * Ïƒ_wT / Ïƒ_T .* derivatives.cell * wT

    return [âˆ‚uâˆ‚t; âˆ‚vâˆ‚t; âˆ‚Tâˆ‚t]
end

function predict_NDE(uw_NN, vw_NN, wT_NN, x, BCs, conditions, scalings, constants, derivatives, filters)
    Nz, H, Ï„, f = constants.Nz, constants.H, constants.Ï„, constants.f
    Ïƒ_uw, Ïƒ_vw, Ïƒ_wT = scalings.uw.Ïƒ, scalings.vw.Ïƒ, scalings.wT.Ïƒ
    Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T = scalings.u.Î¼, scalings.v.Î¼, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ

    u = @view x[1:Nz]
    v = @view x[Nz + 1:2Nz]
    T = @view x[2Nz + 1:3Nz]

    uw, vw, wT = predict_flux(uw_NN, vw_NN, wT_NN, x, BCs, conditions, scalings, constants, derivatives, filters)
    
    âˆ‚uâˆ‚t = -Ï„ / H * Ïƒ_uw / Ïƒ_u .* derivatives.cell * uw .+ f * Ï„ / Ïƒ_u .* (Ïƒ_v .* v .+ Î¼_v)
    âˆ‚vâˆ‚t = -Ï„ / H * Ïƒ_vw / Ïƒ_v .* derivatives.cell * vw .- f * Ï„ / Ïƒ_v .* (Ïƒ_u .* u .+ Î¼_u)
    âˆ‚Tâˆ‚t = -Ï„ / H * Ïƒ_wT / Ïƒ_T .* derivatives.cell * wT

    return [âˆ‚uâˆ‚t; âˆ‚vâˆ‚t; âˆ‚Tâˆ‚t]
end

function prepare_training_data!(ğ’Ÿtrain, tsteps, n_simulations)
    u_trains = [interior(ğ’Ÿtrain.data[i]["u*"])[1,1,:,tsteps[i][1]] for i in 1:n_simulations]
    v_trains = [interior(ğ’Ÿtrain.data[i]["v*"])[1,1,:,tsteps[i][1]] for i in 1:n_simulations]
    T_trains = [interior(ğ’Ÿtrain.data[i]["T*"])[1,1,:,tsteps[i][1]] for i in 1:n_simulations]

    uvTâ‚€s = [
        [u_trains[i][:,1]; v_trains[i][:,1]; T_trains[i][:,1]] for i in 1:n_simulations
    ]

    âˆ‚uâˆ‚zs = [interior(ğ’Ÿtrain.data[i]["âˆ‚uâˆ‚z*"])[1,1,:,tsteps[i][1]] for i in 1:n_simulations]
    âˆ‚vâˆ‚zs = [interior(ğ’Ÿtrain.data[i]["âˆ‚vâˆ‚z*"])[1,1,:,tsteps[i][1]] for i in 1:n_simulations]
    âˆ‚Tâˆ‚zs = [interior(ğ’Ÿtrain.data[i]["âˆ‚Tâˆ‚z*"])[1,1,:,tsteps[i][1]] for i in 1:n_simulations]

    t_trains = [Float32.(ğ’Ÿtrain.data[i]["u"].times[tsteps[i]]) for i in 1:n_simulations]
    @assert typeof(t_trains[1][1]) == Float32

    for i in 1:n_simulations
        ğ’Ÿtrain.data[i].metadata["Ï„"] = t_trains[i][end]
    end

    t_trains .= [times ./ times[end] for times in t_trains]
    tspan_trains = [(t[1], t[end]) for t in t_trains]

    profiles = (u=u_trains, v=v_trains, T=T_trains, âˆ‚uâˆ‚z=âˆ‚uâˆ‚zs, âˆ‚vâˆ‚z=âˆ‚vâˆ‚zs, âˆ‚Tâˆ‚z=âˆ‚Tâˆ‚zs)
    times = (t=t_trains, tspan=tspan_trains)

    return profiles, uvTâ‚€s, times
end

#TODO: add diurnal functionality
function train_NDE(uw_NN, vw_NN, wT_NN, train_files, tsteps, timestepper, optimizers, epochs, FILE_PATH; 
                    maxiters=500, diffusivity_scheme=RiBasedDiffusivity(1f-4, 1f-1, 1f-1, 0.25f0, 1f0), train_gradient=false,
                    zero_weights=false, gradient_scaling=5f-3, training_fractions=nothing, diurnal=false, 
                    Nz=32, scaling=ZeroMeanUnitVarianceScaling)

    train_parameters = Dict(
               "diffusivity_scheme" => diffusivity_scheme,
                   "train_gradient" => train_gradient,
                     "zero_weights" => zero_weights, 
                 "gradient_scaling" => gradient_scaling, 
               "training_fractions" => training_fractions,
                          "diurnal" => diurnal
    )

    @info "Loading training data"

    ğ’Ÿtrain = load_data(train_files, Nz_coarse=Nz, scaling=scaling)

    @info "Setting up constants"
    
    n_simulations = length(ğ’Ÿtrain.data)

    conditions = (train_gradient=train_gradient, zero_weights=zero_weights, diurnal=diurnal)
    
    derivatives, NN_constructions, weights, NN_ranges = prepare_parameters_NDE_training(uw_NN, vw_NN, wT_NN, Nz)

    @info "Setting up training data"

    !isa(tsteps, Array) && (tsteps = [tsteps for i in 1:n_simulations])

    training_profiles, uvTâ‚€s, times = prepare_training_data!(ğ’Ÿtrain, tsteps, n_simulations)

    @info "Setting up equations and boundary conditions"

    BCs = [
        [
            interior(dataset["wu*"])[1,1,1,1], interior(dataset["wu*"])[1,1,end,1],
            interior(dataset["wv*"])[1,1,1,1], interior(dataset["wv*"])[1,1,end,1],
            interior(dataset["wT*"])[1,1,1,1], interior(dataset["wT*"])[1,1,end,1],
        ]
        for dataset in ğ’Ÿtrain.data
    ]

    if diurnal
        # prob_NDEs = [
        #     ODEProblem(
        #         (x, p, t) -> NDE(x, p, t, NN_ranges, NN_constructions, conditions, scalings, constants, derivatives, filters, wT_top_functions[i]), uvTâ‚€s[i], tspan_train
        #     ) for i in 1:n_simulations
        # ]
        error("Diurnal Flux not Implemented yet")
    else
        prob_NDEs = [ODEProblem((x, p, t) -> NDE(x, p, t, ğ’Ÿtrain.data[i], NN_ranges, NN_constructions, conditions, derivatives, diffusivity_scheme), 
                                    uvTâ‚€s[i], times.tspan[i]) for i in 1:n_simulations]
    end

    function determine_loss_scalings()
        if training_fractions === nothing
            loss_scalings = (u=1, v=1, T=1, âˆ‚uâˆ‚z=gradient_scaling, âˆ‚vâˆ‚z=gradient_scaling, âˆ‚Tâˆ‚z=gradient_scaling)
        else
            sols = [Array(solve(prob_NDEs[i], timestepper, p=[weights; BCs[i]], reltol=1f-3, sensealg=InterpolatingAdjoint(autojacvec=ZygoteVJP()), saveat=times.t[i])) for i in 1:n_simulations]        
            u_sols, v_sols, T_sols = split_u.(sols, Nz), split_v.(sols, Nz), split_T.(sols, Nz)

            u_loss = [loss(training_profiles.u[i], u_sols[i]) for i in 1:n_simulations] |> mean
            v_loss = [loss(training_profiles.v[i], v_sols[i]) for i in 1:n_simulations] |> mean
            T_loss = [loss(training_profiles.T[i], T_sols[i]) for i in 1:n_simulations] |> mean
    
            if train_gradient
                u_sols_gradients = [âˆ‚_âˆ‚z(sol, derivatives.face) for sol in u_sols]
                v_sols_gradients = [âˆ‚_âˆ‚z(sol, derivatives.face) for sol in v_sols]
                T_sols_gradients = [âˆ‚_âˆ‚z(sol, derivatives.face) for sol in T_sols]

                âˆ‚uâˆ‚z_loss = [loss(training_profiles.âˆ‚uâˆ‚z[i], u_sols_gradients[i]) for i in 1:n_simulations] |> mean
                âˆ‚vâˆ‚z_loss = [loss(training_profiles.âˆ‚vâˆ‚z[i], v_sols_gradients[i]) for i in 1:n_simulations] |> mean
                âˆ‚Tâˆ‚z_loss = [loss(training_profiles.âˆ‚Tâˆ‚z[i], T_sols_gradients[i]) for i in 1:n_simulations] |> mean
            else
                âˆ‚uâˆ‚z_loss = 0
                âˆ‚vâˆ‚z_loss = 0
                âˆ‚Tâˆ‚z_loss = 0
            end

            losses = (u=u_loss, v=v_loss, T=T_loss, âˆ‚uâˆ‚z=âˆ‚uâˆ‚z_loss, âˆ‚vâˆ‚z=âˆ‚vâˆ‚z_loss, âˆ‚Tâˆ‚z=âˆ‚Tâˆ‚z_loss)
            loss_scalings = calculate_loss_scalings(losses, training_fractions, train_gradient)
        end
        return loss_scalings
    end

    @info "Determining training scalings"

    loss_scalings = determine_loss_scalings()

    @info "Defining Loss Functions"

    function loss_NDE(weights, BCs)
        sols = [Array(solve(prob_NDEs[i], timestepper, p=[weights; BCs[i]], reltol=1f-3, sensealg=InterpolatingAdjoint(autojacvec=ZygoteVJP()), saveat=times.t[i])) for i in 1:n_simulations]        
        u_sols, v_sols, T_sols = split_u.(sols, Nz), split_v.(sols, Nz), split_T.(sols, Nz)

        u_loss = [loss(training_profiles.u[i], u_sols[i]) for i in 1:n_simulations] |> mean
        v_loss = [loss(training_profiles.v[i], v_sols[i]) for i in 1:n_simulations] |> mean
        T_loss = [loss(training_profiles.T[i], T_sols[i]) for i in 1:n_simulations] |> mean

        losses = (u=u_loss, v=v_loss, T=T_loss, âˆ‚uâˆ‚z=0, âˆ‚vâˆ‚z=0, âˆ‚Tâˆ‚z=0)
        scaled_losses = apply_loss_scalings(losses, loss_scalings)

        return sum(scaled_losses), scaled_losses, loss_scalings
    end

    function loss_gradient_NDE(weights, BCs)
        sols = [Array(solve(prob_NDEs[i], timestepper, p=[weights; BCs[i]], reltol=1f-3, sensealg=InterpolatingAdjoint(autojacvec=ZygoteVJP()), saveat=times.t[i])) for i in 1:n_simulations]
        # sols = [Array(solve(prob_NDEs[i], timestepper, p=[weights; BCs[i]], reltol=1f-3, saveat=t_trains[i])) for i in 1:n_simulations]

        u_sols, v_sols, T_sols = split_u.(sols, Nz), split_v.(sols, Nz), split_T.(sols, Nz)

        u_sols_gradients = [âˆ‚_âˆ‚z(sol, derivatives.face) for sol in u_sols]
        v_sols_gradients = [âˆ‚_âˆ‚z(sol, derivatives.face) for sol in v_sols]
        T_sols_gradients = [âˆ‚_âˆ‚z(sol, derivatives.face) for sol in T_sols]

        u_loss = [loss(training_profiles.u[i], u_sols[i]) for i in 1:n_simulations] |> mean
        v_loss = [loss(training_profiles.v[i], v_sols[i]) for i in 1:n_simulations] |> mean
        T_loss = [loss(training_profiles.T[i], T_sols[i]) for i in 1:n_simulations] |> mean

        âˆ‚uâˆ‚z_loss = [loss(training_profiles.âˆ‚uâˆ‚z[i], u_sols_gradients[i]) for i in 1:n_simulations] |> mean
        âˆ‚vâˆ‚z_loss = [loss(training_profiles.âˆ‚vâˆ‚z[i], v_sols_gradients[i]) for i in 1:n_simulations] |> mean
        âˆ‚Tâˆ‚z_loss = [loss(training_profiles.âˆ‚Tâˆ‚z[i], T_sols_gradients[i]) for i in 1:n_simulations] |> mean
        
        losses = (u=u_loss, v=v_loss, T=T_loss, âˆ‚uâˆ‚z=âˆ‚uâˆ‚z_loss, âˆ‚vâˆ‚z=âˆ‚vâˆ‚z_loss, âˆ‚Tâˆ‚z=âˆ‚Tâˆ‚z_loss)
        scaled_losses = apply_loss_scalings(losses, loss_scalings)

        return sum(scaled_losses), scaled_losses, loss_scalings, T_sols
    end

    @info "Setting up optimization problem"

    if train_gradient
        f_loss = OptimizationFunction(loss_gradient_NDE, GalacticOptim.AutoZygote())
    else
        f_loss = OptimizationFunction(loss_NDE, GalacticOptim.AutoZygote())
    end

    prob_loss = OptimizationProblem(f_loss, weights, BCs)

    @inline function rounded_percentage(num, den)
        return round(num / den * 100, sigdigits=3)
    end

    @info "Starting Training"
    for i in 1:length(optimizers), epoch in 1:epochs
        iter = 1
        opt = optimizers[i]
        function cb(args...)
            if iter <= maxiters
                total_loss = args[2]
                losses = args[3]
                loss_scalings = args[4]

                T_sols = args[5]

                profile_loss = losses.u + losses.v + losses.T
                gradient_loss = losses.âˆ‚uâˆ‚z + losses.âˆ‚vâˆ‚z + losses.âˆ‚Tâˆ‚z

                profile_percent = rounded_percentage(profile_loss, total_loss)
                gradient_percent = rounded_percentage(gradient_loss, total_loss)
                u_percent = rounded_percentage(losses.u, total_loss)
                v_percent = rounded_percentage(losses.v, total_loss)
                T_percent = rounded_percentage(losses.T, total_loss)
                âˆ‚uâˆ‚z_percent = rounded_percentage(losses.âˆ‚uâˆ‚z, total_loss)
                âˆ‚vâˆ‚z_percent = rounded_percentage(losses.âˆ‚vâˆ‚z, total_loss)
                âˆ‚Tâˆ‚z_percent = rounded_percentage(losses.âˆ‚Tâˆ‚z, total_loss)

                @info "loss = $(total_loss): uvT$(profile_percent)% grad$(gradient_percent)% u$(u_percent)% v$(v_percent)% T$(T_percent)% âˆ‚uâˆ‚z$(âˆ‚uâˆ‚z_percent)% âˆ‚vâˆ‚z$(âˆ‚vâˆ‚z_percent)% âˆ‚Tâˆ‚z$(âˆ‚Tâˆ‚z_percent)% opt$i/$(length(optimizers)) epoch$epoch/$epochs iter$iter/$maxiters"
                write_data_NDE_training(FILE_PATH, losses, loss_scalings,
                                    NN_constructions.uw(args[1][NN_ranges.uw]), 
                                    NN_constructions.vw(args[1][NN_ranges.vw]), 
                                    NN_constructions.wT(args[1][NN_ranges.wT]), 
                                    opt)
            end
            iter += 1
            false
        end
        res = solve(prob_loss, opt, cb=cb, maxiters=maxiters)
        weights .= res.minimizer
    end
    return NN_constructions.uw(weights[NN_ranges.uw]), NN_constructions.vw(weights[NN_ranges.vw]), NN_constructions.wT(weights[NN_ranges.wT])
end


function train_NDE(uw_NN, vw_NN, wT_NN, train_files, tsteps, timestepper, optimizers, epochs, FILE_PATH, stage; 
                    maxiters=500, Î½â‚€=1f-4, Î½â‚‹=1f-1, Î”Ri=1f0, Riá¶œ=0.25, Pr=1f0, Îº=10f0, f=1f-4, Î±=2f-4, g=9.80665f0, 
                    modified_pacanowski_philander=false, convective_adjustment=false, smooth_profile=false, smooth_NN=false, smooth_Ri=false, train_gradient=false,
                    zero_weights=false, gradient_scaling=5f-3, training_fractions=nothing, diurnal=false)
    @assert !modified_pacanowski_philander || !convective_adjustment

    train_parameters = Dict(
                               "Î½â‚€" => Î½â‚€, 
                               "Î½â‚‹" => Î½â‚‹, 
                              "Î”Ri" => Î”Ri, 
                              "Riá¶œ" => Riá¶œ, 
                               "Pr" => Pr, 
                                "Îº" => Îº,
    "modified_pacanowski_philander" => modified_pacanowski_philander, 
            "convective_adjustment" => convective_adjustment,
                   "smooth_profile" => smooth_profile, 
                        "smooth_NN" => smooth_NN, 
                        "smooth_Ri" => smooth_Ri, 
                   "train_gradient" => train_gradient,
                     "zero_weights" => zero_weights, 
                 "gradient_scaling" => gradient_scaling, 
               "training_fractions" => training_fractions,
                          "diurnal" => diurnal
    )

    if zero_weights
        @assert modified_pacanowski_philander
    end

    @info "Loading training data"

    ğ’Ÿtrain = WindMixing.data(train_files, scale_type=ZeroMeanUnitVarianceScaling, enforce_surface_fluxes=false)

    @info "Setting up constants"
    
    n_simulations = length(train_files)
    Nz = length(ğ’Ÿtrain.u.z)

    conditions = (modified_pacanowski_philander=modified_pacanowski_philander, convective_adjustment=convective_adjustment, 
                    smooth_profile=smooth_profile, smooth_NN=smooth_NN, smooth_Ri=smooth_Ri, 
                    train_gradient=train_gradient, zero_weights=zero_weights, diurnal=diurnal)
    
    constants, scalings, derivatives, NN_constructions, weights, NN_sizes, NN_ranges, filters = prepare_parameters_NDE_training(ğ’Ÿtrain, uw_NN, vw_NN, wT_NN, f, Nz, g, Î±, Î½â‚€, Î½â‚‹, Riá¶œ, Î”Ri, Pr, Îº, conditions)
    D_face = derivatives.face

    n_steps = Int(length(@view(ğ’Ÿtrain.t[:,1])) / n_simulations)

    if diurnal
        wT_top_functions = diurnal_fluxes(train_files, constants)
    end

    @info "Setting up training data"

    uvTâ‚€s = [ğ’Ÿtrain.uvT_scaled[:,n_steps * i + tsteps[1]] for i in 0:n_simulations - 1]
    t_train = ğ’Ÿtrain.t[:,1][tsteps]
    uvT_trains = [ğ’Ÿtrain.uvT_scaled[:,n_steps * i + 1:n_steps * (i + 1)][:, tsteps] for i in 0:n_simulations - 1]

    u_trains, v_trains, T_trains = split_u.(uvT_trains, Nz), split_v.(uvT_trains, Nz), split_T.(uvT_trains, Nz)

    if train_gradient
        u_trains_gradients = [âˆ‚_âˆ‚z(sol, D_face) for sol in u_trains]
        v_trains_gradients = [âˆ‚_âˆ‚z(sol, D_face) for sol in v_trains]
        T_trains_gradients = [âˆ‚_âˆ‚z(sol, D_face) for sol in T_trains]
    end

    @info "Setting up equations and boundary conditions"


    t_train = t_train ./ constants.Ï„
    tspan_train = (t_train[1], t_train[end])

    BCs = [[ğ’Ÿtrain.uw.scaled[1,n_steps * i + tsteps[1]],
        ğ’Ÿtrain.uw.scaled[end,n_steps * i + tsteps[1]],
        ğ’Ÿtrain.vw.scaled[1,n_steps * i + tsteps[1]],
        ğ’Ÿtrain.vw.scaled[end,n_steps * i + tsteps[1]],
        ğ’Ÿtrain.wT.scaled[1,n_steps * i + tsteps[1]],
        ğ’Ÿtrain.wT.scaled[end,n_steps * i + tsteps[1]]] for i in 0:n_simulations - 1]

    if diurnal
        prob_NDEs = [
            ODEProblem(
                (x, p, t) -> NDE(x, p, t, NN_ranges, NN_constructions, conditions, scalings, constants, derivatives, filters, wT_top_functions[i]), uvTâ‚€s[i], tspan_train
            ) for i in 1:n_simulations
        ]
    else
        prob_NDE(x, p, t) = NDE(x, p, t, NN_ranges, NN_constructions, conditions, scalings, constants, derivatives, filters)
        prob_NDEs = [ODEProblem(prob_NDE, uvTâ‚€s[i], tspan_train) for i in 1:n_simulations]
    end

    function determine_loss_scalings()
        if training_fractions === nothing
            loss_scalings = (u=1, v=1, T=1, âˆ‚uâˆ‚z=gradient_scaling, âˆ‚vâˆ‚z=gradient_scaling, âˆ‚Tâˆ‚z=gradient_scaling)
        else
            sols = [Array(solve(prob_NDEs[i], timestepper, p=[weights; BCs[i]], reltol=1f-3, sensealg=InterpolatingAdjoint(autojacvec=ZygoteVJP()), saveat=t_train)) for i in 1:n_simulations]        
            u_sols, v_sols, T_sols = split_u.(sols, Nz), split_v.(sols, Nz), split_T.(sols, Nz)

            u_loss = mean(loss.(u_trains, u_sols))
            v_loss = mean(loss.(v_trains, v_sols))
            T_loss = mean(loss.(T_trains, T_sols))
            if train_gradient
                u_sols_gradients = [âˆ‚_âˆ‚z(sol, D_face) for sol in u_sols]
                v_sols_gradients = [âˆ‚_âˆ‚z(sol, D_face) for sol in v_sols]
                T_sols_gradients = [âˆ‚_âˆ‚z(sol, D_face) for sol in T_sols]

                âˆ‚uâˆ‚z_loss = mean(loss.(u_trains_gradients, u_sols_gradients))
                âˆ‚vâˆ‚z_loss = mean(loss.(v_trains_gradients, v_sols_gradients))
                âˆ‚Tâˆ‚z_loss = mean(loss.(T_trains_gradients, T_sols_gradients))
            else
                âˆ‚uâˆ‚z_loss = 0
                âˆ‚vâˆ‚z_loss = 0
                âˆ‚Tâˆ‚z_loss = 0
            end

            losses = (u=u_loss, v=v_loss, T=T_loss, âˆ‚uâˆ‚z=âˆ‚uâˆ‚z_loss, âˆ‚vâˆ‚z=âˆ‚vâˆ‚z_loss, âˆ‚Tâˆ‚z=âˆ‚Tâˆ‚z_loss)
            loss_scalings = calculate_loss_scalings(losses, training_fractions, train_gradient)
        end
        return loss_scalings
    end

    @info "Determining training scalings"

    loss_scalings = determine_loss_scalings()

    function loss_NDE(weights, BCs)
        sols = [Array(solve(prob_NDEs[i], timestepper, p=[weights; BCs[i]], reltol=1f-3, sensealg=InterpolatingAdjoint(autojacvec=ZygoteVJP()), saveat=t_train)) for i in 1:n_simulations]        
        u_sols, v_sols, T_sols = split_u.(sols, Nz), split_v.(sols, Nz), split_T.(sols, Nz)
        u_loss = mean(loss.(u_trains, u_sols))
        v_loss = mean(loss.(v_trains, v_sols))
        T_loss = mean(loss.(T_trains, T_sols))

        losses = (u=u_loss, v=v_loss, T=T_loss, âˆ‚uâˆ‚z=0, âˆ‚vâˆ‚z=0, âˆ‚Tâˆ‚z=0)
        scaled_losses = apply_loss_scalings(losses, loss_scalings)

        return sum(scaled_losses), scaled_losses, loss_scalings
    end

    function loss_gradient_NDE(weights, BCs)
        sols = [Array(solve(prob_NDEs[i], timestepper, p=[weights; BCs[i]], reltol=1f-3, sensealg=InterpolatingAdjoint(autojacvec=ZygoteVJP()), saveat=t_train)) for i in 1:n_simulations]

        u_sols, v_sols, T_sols = split_u.(sols, Nz), split_v.(sols, Nz), split_T.(sols, Nz)

        u_sols_gradients = [âˆ‚_âˆ‚z(sol, D_face) for sol in u_sols]
        v_sols_gradients = [âˆ‚_âˆ‚z(sol, D_face) for sol in v_sols]
        T_sols_gradients = [âˆ‚_âˆ‚z(sol, D_face) for sol in T_sols]

        u_loss = mean(loss.(u_trains, u_sols))
        v_loss = mean(loss.(v_trains, v_sols))
        T_loss = mean(loss.(T_trains, T_sols))
        âˆ‚uâˆ‚z_loss = mean(loss.(u_trains_gradients, u_sols_gradients))
        âˆ‚vâˆ‚z_loss = mean(loss.(v_trains_gradients, v_sols_gradients))
        âˆ‚Tâˆ‚z_loss = mean(loss.(T_trains_gradients, T_sols_gradients))
        
        losses = (u=u_loss, v=v_loss, T=T_loss, âˆ‚uâˆ‚z=âˆ‚uâˆ‚z_loss, âˆ‚vâˆ‚z=âˆ‚vâˆ‚z_loss, âˆ‚Tâˆ‚z=âˆ‚Tâˆ‚z_loss)
        scaled_losses = apply_loss_scalings(losses, loss_scalings)

        return sum(scaled_losses), scaled_losses, loss_scalings
    end

    @info "Setting up optimization problem"

    if train_gradient
        f_loss = OptimizationFunction(loss_gradient_NDE, GalacticOptim.AutoZygote())
    else
        f_loss = OptimizationFunction(loss_NDE, GalacticOptim.AutoZygote())
    end

    prob_loss = OptimizationProblem(f_loss, @view(weights[:]), BCs)

    @inline function rounded_percentage(num, den)
        return round(num / den * 100, sigdigits=3)
    end

    @info "Starting Training"
    for i in 1:length(optimizers), epoch in 1:epochs
        iter = 1
        opt = optimizers[i]
        function cb(args...)
            if iter <= maxiters
                total_loss = args[2]
                losses = args[3]
                loss_scalings = args[4]
                profile_loss = losses.u + losses.v + losses.T
                gradient_loss = losses.âˆ‚uâˆ‚z + losses.âˆ‚vâˆ‚z + losses.âˆ‚Tâˆ‚z

                profile_percent = rounded_percentage(profile_loss, total_loss)
                gradient_percent = rounded_percentage(gradient_loss, total_loss)
                u_percent = rounded_percentage(losses.u, total_loss)
                v_percent = rounded_percentage(losses.v, total_loss)
                T_percent = rounded_percentage(losses.T, total_loss)
                âˆ‚uâˆ‚z_percent = rounded_percentage(losses.âˆ‚uâˆ‚z, total_loss)
                âˆ‚vâˆ‚z_percent = rounded_percentage(losses.âˆ‚vâˆ‚z, total_loss)
                âˆ‚Tâˆ‚z_percent = rounded_percentage(losses.âˆ‚Tâˆ‚z, total_loss)

                @info "loss = $(total_loss): uvT$(profile_percent)% grad$(gradient_percent)% u$(u_percent)% v$(v_percent)% T$(T_percent)% âˆ‚uâˆ‚z$(âˆ‚uâˆ‚z_percent)% âˆ‚vâˆ‚z$(âˆ‚vâˆ‚z_percent)% âˆ‚Tâˆ‚z$(âˆ‚Tâˆ‚z_percent)% $stage opt$i/$(length(optimizers)) epoch$epoch/$epochs iter$iter/$maxiters"
                write_data_NDE_training(FILE_PATH, losses, loss_scalings,
                                    NN_constructions.uw(args[1][NN_ranges.uw]), 
                                    NN_constructions.vw(args[1][NN_ranges.vw]), 
                                    NN_constructions.wT(args[1][NN_ranges.wT]), 
                                    stage, opt)
            end
            iter += 1
            false
        end
        res = solve(prob_loss, opt, cb=cb, maxiters=maxiters)
        weights .= res.minimizer
    end
    return NN_constructions.uw(weights[NN_ranges.uw]), NN_constructions.vw(weights[NN_ranges.vw]), NN_constructions.wT(weights[NN_ranges.wT])
end

function solve_NDE_nonmutating(uw_NN, vw_NN, wT_NN, ğ’Ÿtrain, tsteps, timestepper; 
                                n_simulations, Î½â‚€=1f-4, Î½â‚‹=1f-1, Î”Ri=1f0, Riá¶œ=0.25, Pr=1f0, Îº=10f0, f=1f-4, Î±=1.67f-4, g=9.81f0)
    Nz = length(ğ’Ÿtrain.u.z)

    conditions = (modified_pacanowski_philander=true, convective_adjustment=false, 
                    smooth_profile=false, smooth_NN=false, smooth_Ri=false, 
                    train_gradient=true, zero_weights=true)
    
    constants, scalings, derivatives, NN_constructions, weights, NN_sizes, NN_ranges, filters = prepare_parameters_NDE_training(ğ’Ÿtrain, uw_NN, vw_NN, wT_NN, f, Nz, g, Î±, Î½â‚€, Î½â‚‹, Riá¶œ, Î”Ri, Pr, Îº, conditions)
    
    n_steps = Int(length(@view(ğ’Ÿtrain.t[:,1])) / n_simulations)

    uvTâ‚€s = [ğ’Ÿtrain.uvT_scaled[:,n_steps * i + tsteps[1]] for i in 0:n_simulations - 1]
    t_train = ğ’Ÿtrain.t[:,1][tsteps]

    prob_NDE(x, p, t) = NDE(x, p, t, NN_ranges, NN_constructions, conditions, scalings, constants, derivatives, filters)

    t_train = t_train ./ constants.Ï„
    tspan_train = (t_train[1], t_train[end])
    BCs = [[ğ’Ÿtrain.uw.scaled[1,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.uw.scaled[end,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.vw.scaled[1,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.vw.scaled[end,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.wT.scaled[1,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.wT.scaled[end,n_steps * i + tsteps[1]]] for i in 0:n_simulations - 1]

    prob_NDEs = [ODEProblem(prob_NDE, uvTâ‚€s[i], tspan_train) for i in 1:n_simulations]
    sols = [Array(solve(prob_NDEs[i], timestepper, p=[weights; BCs[i]], reltol=1f-3, sensealg=InterpolatingAdjoint(autojacvec=ZygoteVJP()), saveat=t_train)) for i in 1:n_simulations]        

    return sols
end

function solve_NDE_nonmutating_backprop(uw_NN, vw_NN, wT_NN, ğ’Ÿtrain, tsteps, timestepper, optimizer; 
                                maxiters, n_simulations, gradient_scaling, Î½â‚€=1f-4, Î½â‚‹=1f-1, Î”Ri=1f0, Riá¶œ=0.25, Pr=1f0, Îº=10f0, f=1f-4, Î±=1.67f-4, g=9.81f0)

    Nz = length(ğ’Ÿtrain.u.z)

    conditions = (modified_pacanowski_philander=true, convective_adjustment=false, 
    smooth_profile=false, smooth_NN=false, smooth_Ri=false, 
    train_gradient=true, zero_weights=true)

    constants, scalings, derivatives, NN_constructions, weights, NN_sizes, NN_ranges, filters = prepare_parameters_NDE_training(ğ’Ÿtrain, uw_NN, vw_NN, wT_NN, f, Nz, g, Î±, Î½â‚€, Î½â‚‹, Riá¶œ, Î”Ri, Pr, Îº, conditions)

    n_steps = Int(length(@view(ğ’Ÿtrain.t[:,1])) / n_simulations)

    uvTâ‚€s = [ğ’Ÿtrain.uvT_scaled[:,n_steps * i + tsteps[1]] for i in 0:n_simulations - 1]
    t_train = ğ’Ÿtrain.t[:,1][tsteps]
    uvT_trains = [ğ’Ÿtrain.uvT_scaled[:,n_steps * i + 1:n_steps * (i + 1)][:, tsteps] for i in 0:n_simulations - 1]

    D_face = derivatives.face

    uvT_gradients = [calculate_profile_gradient(uvT, derivatives, constants) for uvT in uvT_trains]

    prob_NDE(x, p, t) = NDE(x, p, t, NN_ranges, NN_constructions, conditions, scalings, constants, derivatives, filters)

    t_train = t_train ./ constants.Ï„
    tspan_train = (t_train[1], t_train[end])
    BCs = [[ğ’Ÿtrain.uw.scaled[1,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.uw.scaled[end,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.vw.scaled[1,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.vw.scaled[end,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.wT.scaled[1,n_steps * i + tsteps[1]],
            ğ’Ÿtrain.wT.scaled[end,n_steps * i + tsteps[1]]] for i in 0:n_simulations - 1]

    prob_NDEs = [ODEProblem(prob_NDE, uvTâ‚€s[i], tspan_train) for i in 1:n_simulations]

    function loss_gradient_NDE(weights, BCs)
        sols = [Array(solve(prob_NDEs[i], timestepper, p=[weights; BCs[i]], reltol=1f-3, sensealg=InterpolatingAdjoint(autojacvec=ZygoteVJP()), saveat=t_train)) for i in 1:n_simulations]
        sol_gradients = [calculate_profile_gradient(sol, derivatives, constants) for sol in sols]
        return mean(loss_gradient.(uvT_trains, sols, uvT_gradients, sol_gradients, gradient_scaling))
    end

    f_loss = OptimizationFunction(loss_gradient_NDE, GalacticOptim.AutoZygote())
    prob_loss = OptimizationProblem(f_loss, weights, BCs)

    iter = 1
    function cb(args...)
        @info "NDE, loss = $(args[2]), iteration = $iter/$maxiters"
        iter += 1
        false
    end

    res = solve(prob_loss, optimizer, cb=cb, maxiters=maxiters)
    weights .= res.minimizer
    return NN_constructions.uw(weights[NN_ranges.uw]), NN_constructions.vw(weights[NN_ranges.vw]), NN_constructions.wT(weights[NN_ranges.wT])
end

using Oceananigans.Grids: Center, Face

"""
    coarse_grain(Î¦, n, ::Type{Center})

Average or coarse grain a `Center`-centered field `Î¦` down to size `n`. `Î¦` is required to have evenly spaced points and `n` needs to evenly divide `length(Î¦)`.
"""
function coarse_grain(Î¦, n, ::Type{Center})
    N = length(Î¦)
    Î” = Int(N / n)
    Î¦Ì… = similar(Î¦, n)
    for i in 1:n
        Î¦Ì…[i] = mean(Î¦[Î”*(i-1)+1:Î”*i])
    end
    return Î¦Ì…
end

"""
    coarse_grain(Î¦, n, ::Type{Face})

Average or coarse grain a `Face`-centered field `Î¦` down to size `n`. `Î¦` is required to have evenly spaced points. The values at the left and right endpoints of `Î¦` will be preserved in the output.
"""
function coarse_grain(Î¦, n, ::Type{Face})
    N = length(Î¦)
    Î¦Ì… = similar(Î¦, n)
    Î” = (N-2) / (n-2)
    Î¦Ì…[1], Î¦Ì…[n] = Î¦[1], Î¦[N]

    if isinteger(Î”)
        Î¦Ì…[2:n-1] .= coarse_grain(Î¦[2:N-1], n-2, Center)
    else
        for i in 2:n-1
            i1 = round(Int, 2 + (i-2)*Î”)
            i2 = round(Int, 2 + (i-1)*Î”)
            Î¦Ì…[i] = mean(Î¦[i1:i2])
        end
    end

    return Î¦Ì…
end

"""
    coarse_grain_linear_interpolation(Î¦, n, ::Type{Face})

Average or coarse grain a `Face`-centered field `Î¦` down to size `n` using linear interpolation. `Î¦` is required to have evenly spaced points. The values at the left and right endpoints of `Î¦` will be preserved in the output.
"""
function coarse_grain_linear_interpolation(Î¦, n, ::Type{Face})
    N = length(Î¦)
    Î¦Ì… = similar(Î¦, n)
    Î¦Ì…[1] = Î¦[1]
    Î¦Ì…[end] = Î¦[end]
    gap = (N-1)/(n-1)

    for i=2:n-1
        Î¦Ì…[i] = 1 + (i-1)*gap
    end

    for i=2:n-1
        Î¦Ì…[i] = (floor(Î¦Ì…[i])+1 - Î¦Ì…[i]) * Î¦[Int(floor(Î¦Ì…[i]))] + (Î¦Ì…[i] - floor(Î¦Ì…[i])) * Î¦[Int(floor(Î¦Ì…[i]))+1]
    end
    return Î¦Ì…
end