function prepare_parameters_NN_training(ğ’Ÿtrain, f, Nz, g, Î±, Î½â‚€, Î½â‚‹, Riá¶œ, Î”Ri, Pr, Îº, conditions)
    H = abs(ğ’Ÿtrain.uw.z[end] - ğ’Ÿtrain.uw.z[1])
    Ï„ = abs(ğ’Ÿtrain.t[:,1][end] - ğ’Ÿtrain.t[:,1][1])
    u_scaling = ğ’Ÿtrain.scalings["u"]
    v_scaling = ğ’Ÿtrain.scalings["v"]
    T_scaling = ğ’Ÿtrain.scalings["T"]
    uw_scaling = ğ’Ÿtrain.scalings["uw"]
    vw_scaling = ğ’Ÿtrain.scalings["vw"]
    wT_scaling = ğ’Ÿtrain.scalings["wT"]

    if conditions.modified_pacanowski_philander
        constants = (H=H, Ï„=Ï„, f=f, Nz=Nz, g=g, Î±=Î±, Î½â‚€=Î½â‚€, Î½â‚‹=Î½â‚‹, Riá¶œ=Riá¶œ, Î”Ri=Î”Ri, Pr=Pr)
    elseif conditions.convective_adjustment
        constants = (H=H, Ï„=Ï„, f=f, Nz=Nz, g=g, Î±=Î±, Îº=Îº)
    else
        constants = (H=H, Ï„=Ï„, f=f, Nz=Nz, g=g, Î±=Î±)
    end
    scalings = (u=u_scaling, v=v_scaling, T=T_scaling, uw=uw_scaling, vw=vw_scaling, wT=wT_scaling)
    derivatives = (cell=Float32.(Dá¶œ(Nz, 1 / Nz)), face=Float32.(Dá¶ (Nz, 1 / Nz)))

    filters = (cell=WindMixing.smoothing_filter(Nz, 3), face=WindMixing.smoothing_filter(Nz+1, 3), interior=WindMixing.smoothing_filter(Nz-1, 3))
    return constants, scalings, derivatives, filters
end

function predict_uw(NN, x, BCs, conditions, scalings, constants, derivatives, filters)
    Nz, H, Ï„, f = constants.Nz, constants.H, constants.Ï„, constants.f
    uw_scaling, vw_scaling, wT_scaling = scalings.uw, scalings.vw, scalings.wT
    Ïƒ_uw, Ïƒ_vw, Ïƒ_wT = uw_scaling.Ïƒ, vw_scaling.Ïƒ, wT_scaling.Ïƒ
    Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T = scalings.u.Î¼, scalings.v.Î¼, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ
    D_cell, D_face = derivatives.cell, derivatives.face

    u = @view x[1:Nz]
    v = @view x[Nz + 1:2Nz]
    T = @view x[2Nz + 1:3Nz]

    interior = NN(x)

    if conditions.smooth_NN
        interior = filters.interior * interior
    end
    
    if conditions.zero_weights
        uw = [0f0; interior; 0f0]
    else
        uw = [BCs.uw.bottom; interior; BCs.uw.top]
    end

    if conditions.modified_pacanowski_philander
        Ïµ = 1f-7
        âˆ‚uâˆ‚z = D_face * u
        âˆ‚vâˆ‚z = D_face * v
        âˆ‚Tâˆ‚z = D_face * T
        Ri = local_richardson.(âˆ‚uâˆ‚z .+ Ïµ, âˆ‚vâˆ‚z .+ Ïµ, âˆ‚Tâˆ‚z .+ Ïµ, constants.H, constants.g, constants.Î±, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ)

        if conditions.smooth_Ri
            Ri = filters.face * Ri
        end

        Î½ = constants.Î½â‚€ .+ constants.Î½â‚‹ .* tanh_step.((Ri .- constants.Riá¶œ) ./ constants.Î”Ri)

        if conditions.zero_weights
            Î½âˆ‚uâˆ‚z = [-(BCs.uw.bottom - scalings.uw(0f0)); Ïƒ_u / Ïƒ_uw / H .* Î½[2:end-1] .* âˆ‚uâˆ‚z[2:end-1]; -(BCs.uw.top - scalings.uw(0f0))]
        else
            Î½âˆ‚uâˆ‚z = Ïƒ_u / Ïƒ_uw / H .* Î½ .* âˆ‚uâˆ‚z
        end

        return uw .- Î½âˆ‚uâˆ‚z
    else
        return uw
    end
end

function predict_vw(NN, x, BCs, conditions, scalings, constants, derivatives, filters)
    Nz, H, Ï„, f = constants.Nz, constants.H, constants.Ï„, constants.f
    uw_scaling, vw_scaling, wT_scaling = scalings.uw, scalings.vw, scalings.wT
    Ïƒ_uw, Ïƒ_vw, Ïƒ_wT = uw_scaling.Ïƒ, vw_scaling.Ïƒ, wT_scaling.Ïƒ
    Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T = scalings.u.Î¼, scalings.v.Î¼, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ
    D_cell, D_face = derivatives.cell, derivatives.face

    u = @view x[1:Nz]
    v = @view x[Nz + 1:2Nz]
    T = @view x[2Nz + 1:3Nz]

    interior = NN(x)

    if conditions.smooth_NN
        interior = filters.interior * interior
    end
    
    if conditions.zero_weights
        vw = [0f0; interior; 0f0]
    else
        vw = [BCs.vw.bottom; interior; BCs.vw.top]
    end

    if conditions.modified_pacanowski_philander
        Ïµ = 1f-7
        âˆ‚uâˆ‚z = D_face * u
        âˆ‚vâˆ‚z = D_face * v
        âˆ‚Tâˆ‚z = D_face * T
        Ri = local_richardson.(âˆ‚uâˆ‚z .+ Ïµ, âˆ‚vâˆ‚z .+ Ïµ, âˆ‚Tâˆ‚z .+ Ïµ, constants.H, constants.g, constants.Î±, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ)

        if conditions.smooth_Ri
            Ri = filters.face * Ri
        end

        Î½ = constants.Î½â‚€ .+ constants.Î½â‚‹ .* tanh_step.((Ri .- constants.Riá¶œ) ./ constants.Î”Ri)
        if conditions.zero_weights
            Î½âˆ‚vâˆ‚z = [-(BCs.vw.bottom - scalings.vw(0f0)); Ïƒ_v / Ïƒ_vw / H .* Î½[2:end-1] .* âˆ‚vâˆ‚z[2:end-1]; -(BCs.vw.top - scalings.vw(0f0))]
        else
            Î½âˆ‚vâˆ‚z = Ïƒ_v / Ïƒ_vw / H .* Î½ .* âˆ‚vâˆ‚z
        end

        return vw .- Î½âˆ‚vâˆ‚z
    else
        return vw
    end
end

function predict_wT(NN, x, BCs, conditions, scalings, constants, derivatives, filters)
    Nz, H, Ï„, f = constants.Nz, constants.H, constants.Ï„, constants.f
    uw_scaling, vw_scaling, wT_scaling = scalings.uw, scalings.vw, scalings.wT
    Ïƒ_uw, Ïƒ_vw, Ïƒ_wT = uw_scaling.Ïƒ, vw_scaling.Ïƒ, wT_scaling.Ïƒ
    Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T = scalings.u.Î¼, scalings.v.Î¼, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ
    D_cell, D_face = derivatives.cell, derivatives.face

    u = @view x[1:Nz]
    v = @view x[Nz + 1:2Nz]
    T = @view x[2Nz + 1:3Nz]

    interior = NN(x)

    if conditions.smooth_NN
        interior = filters.interior * interior
    end
    
    if conditions.zero_weights
        wT = [0f0; interior; 0f0]
    else
        wT = [BCs.wT.bottom; interior; BCs.wT.top]
    end

    if conditions.modified_pacanowski_philander
        Ïµ = 1f-7
        âˆ‚uâˆ‚z = D_face * u
        âˆ‚vâˆ‚z = D_face * v
        âˆ‚Tâˆ‚z = D_face * T
        Ri = local_richardson.(âˆ‚uâˆ‚z .+ Ïµ, âˆ‚vâˆ‚z .+ Ïµ, âˆ‚Tâˆ‚z .+ Ïµ, constants.H, constants.g, constants.Î±, scalings.u.Ïƒ, scalings.v.Ïƒ, scalings.T.Ïƒ)

        if conditions.smooth_Ri
            Ri = filters.face * Ri
        end

        Î½ = constants.Î½â‚€ .+ constants.Î½â‚‹ .* tanh_step.((Ri .- constants.Riá¶œ) ./ constants.Î”Ri)
        if conditions.zero_weights
            Î½âˆ‚Tâˆ‚z = [-(BCs.wT.bottom - scalings.wT(0f0)); Ïƒ_T / Ïƒ_wT / H .* Î½[2:end-1] ./ constants.Pr .* âˆ‚Tâˆ‚z[2:end-1]; -(BCs.wT.top - scalings.wT(0f0))]
        else
            Î½âˆ‚Tâˆ‚z = Ïƒ_T / Ïƒ_wT / H .* Î½ .* âˆ‚Tâˆ‚z ./ constants.Pr
        end

        return wT .- Î½âˆ‚Tâˆ‚z
    elseif conditions.convective_adjustment
        âˆ‚Tâˆ‚z = D_face * T
        Îºâˆ‚Tâˆ‚z = Ïƒ_T / Ïƒ_wT / H .* Îº .* min.(0f0, âˆ‚Tâˆ‚z)
        return wT .- Îºâˆ‚Tâˆ‚z
    else
        return wT
    end
end

function predict_NN(NN, x, y)
    interior = NN(x)
    return [y[1]; interior; y[end]]
end

function save_NN_weights(weights, FILE_PATH, filename)
    NN_params = Dict(:weights => weights)
    bson(joinpath(FILE_PATH, "$filename.bson"), NN_params)
end

function loss_flux_gradient(NN, )
    
end

function prepare_NN_training_data(ğ’Ÿ, NN_type, derivatives)
    @inline training_data_BCs(ğ’Ÿ, i) = (uw=(top=ğ’Ÿ.uw.scaled[end,i], bottom=ğ’Ÿ.uw.scaled[1,i]), 
                                       vw=(top=ğ’Ÿ.vw.scaled[end,i], bottom=ğ’Ÿ.vw.scaled[1,i]),
                                       wT=(top=ğ’Ÿ.wT.scaled[end,i], bottom=ğ’Ÿ.wT.scaled[1,i]))
    @inline training_data_uw(ğ’Ÿ, i) = ((profile=ğ’Ÿ.uvT_scaled[:,i], BCs=training_data_BCs(ğ’Ÿ,i)), (flux=ğ’Ÿ.uw.scaled[:,i], flux_gradient=calculate_flux_gradient(ğ’Ÿ.uw.scaled[:,i], derivatives)))
    @inline training_data_vw(ğ’Ÿ, i) = ((profile=ğ’Ÿ.uvT_scaled[:,i], BCs=training_data_BCs(ğ’Ÿ,i)), (flux=ğ’Ÿ.vw.scaled[:,i], flux_gradient=calculate_flux_gradient(ğ’Ÿ.vw.scaled[:,i], derivatives)))
    @inline training_data_wT(ğ’Ÿ, i) = ((profile=ğ’Ÿ.uvT_scaled[:,i], BCs=training_data_BCs(ğ’Ÿ,i)), (flux=ğ’Ÿ.wT.scaled[:,i], flux_gradient=calculate_flux_gradient(ğ’Ÿ.wT.scaled[:,i], derivatives)))

    if NN_type == "uw"
        data = [training_data_uw(ğ’Ÿ, i) for i in 1:size(ğ’Ÿ.uw.scaled, 2)]
    elseif NN_type == "vw"
        data = [training_data_vw(ğ’Ÿ, i) for i in 1:size(ğ’Ÿ.vw.scaled, 2)]
    else
        data = [training_data_wT(ğ’Ÿ, i) for i in 1:size(ğ’Ÿ.wT.scaled, 2)]
    end
    return shuffle(data)
end

function calculate_flux_gradient(flux, derivatives)
    return derivatives.cell * flux
end

function train_NN(NN, ğ’Ÿtrain, optimizers, train_epochs, FILE_PATH, NN_type; Î½â‚€=1f-4, Î½â‚‹=1f-1, Î”Ri=1f0, Riá¶œ=0.25, Pr=1f0, Îº=10f0, f=1f-4, Î±=1.67f-4, g=9.81f0, 
                  modified_pacanowski_philander=false, convective_adjustment=false, smooth_profile=false, smooth_NN=false, smooth_Ri=false, train_gradient=false,
                  zero_weights=false, gradient_scaling=1f-4)
    Nz = length(ğ’Ÿtrain.u.z)

    conditions = (modified_pacanowski_philander=modified_pacanowski_philander, convective_adjustment=convective_adjustment, 
                  smooth_profile=smooth_profile, smooth_NN=smooth_NN, smooth_Ri=smooth_Ri, 
                  train_gradient=train_gradient, zero_weights=zero_weights)

    constants, scalings, derivatives, filters = prepare_parameters_NN_training(ğ’Ÿtrain, f, Nz, g, Î±, Î½â‚€, Î½â‚‹, Riá¶œ, Î”Ri, Pr, Îº, conditions)
    training_data = prepare_NN_training_data(ğ’Ÿtrain, NN_type, derivatives)

    function NN_loss(input, output)
        if NN_type == "uw"
            NN_flux = predict_uw(NN, input.profile, input.BCs, conditions, scalings, constants, derivatives, filters)
        elseif NN_type == "vw"
            NN_flux = predict_vw(NN, input.profile, input.BCs, conditions, scalings, constants, derivatives, filters)
        else
            NN_flux = predict_wT(NN, input.profile, input.BCs, conditions, scalings, constants, derivatives, filters)
        end
        âˆ‚z_NN_flux = calculate_flux_gradient(NN_flux, derivatives)
        # return loss(NN_flux, output.flux)

        return loss(NN_flux, output.flux) + gradient_scaling * loss(output.flux_gradient, âˆ‚z_NN_flux)
    end

    function total_loss(training_data)
        return mean([NN_loss(data[1], data[2]) for data in training_data])
    end

    # loss(x, y) = loss_gradient(x, y, calculate_flux_gradient(x, derivatives), calculate_flux_gradient(y, derivatives), gradient_scaling)

    for i in 1:length(optimizers), epoch in 1:train_epochs[i]
        opt = optimizers[i]
        function cb()
            @info "$NN_type NN, loss = $(total_loss(training_data)), opt $i/$(length(optimizers)), epoch $epoch/$(train_epochs[i])"
        end
        Flux.train!(NN_loss, Flux.params(NN), training_data, opt, cb=Flux.throttle(cb,10))
        write_data_NN_training(FILE_PATH, total_loss(training_data), NN)
    end

    return Flux.destructure(NN)[1]
end

