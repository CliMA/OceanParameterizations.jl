using OceanParameterizations
using Flux, OceanTurb, Plots
using DifferentialEquations
using Oceananigans.Grids: Cell, Face

include("lesbrary_data.jl")
include("data_containers.jl")
include("animate_prediction.jl")
output_gif_directory = "Output1"

##

train_files = ["strong_wind", "free_convection"]
test_file = "strong_wind"

##

ğ’Ÿtrain = data(train_files,
                    scale_type=ZeroMeanUnitVarianceScaling,
                    animate=false,
                    animate_dir="$(output_gif_directory)/Training")
ğ’Ÿtest = data(test_file,
                    override_scalings=ğ’Ÿtrain.scalings, # use the scalings from the training data
                    animate=false,
                    animate_dir="$(output_gif_directory)/Testing")

les = read_les_output(test_file)

## Neural Networks

# trained NN models
uw_NN_model = nn_model(ğ’± = ğ’Ÿtrain.uw,
                    model = Chain(Dense(96,96, relu), Dense(96,96, relu), Dense(96,33)),
                    optimizers = [ADAM(), ADAM(), ADAM(), ADAM(), Descent(), Descent(), Descent(), Descent(), Descent()],
                   )

vw_NN_model = nn_model(ğ’± = ğ’Ÿtrain.vw,
                    model = Chain(Dense(96,96, relu), Dense(96,96, relu), Dense(96,33)),
                    optimizers = [ADAM(), ADAM(), ADAM(), ADAM(), Descent(), Descent(), Descent(), Descent(), Descent()],
                   )

wT_NN_model = nn_model(ğ’± = ğ’Ÿtrain.wT,
                    model = Chain(Dense(96,96, relu), Dense(96,96, relu), Dense(96,33)),
                    optimizers = [ADAM(), ADAM(), ADAM(), ADAM(), ADAM(), ADAM(), ADAM(), ADAM(), Descent(), Descent(), Descent(), Descent(), Descent(), Descent()],
                   )

uw_NN = predict(ğ’Ÿtest.uw, uw_NN_model)
vw_NN = predict(ğ’Ÿtest.vw, vw_NN_model)
wT_NN = predict(ğ’Ÿtest.wT, wT_NN_model)

# Compare NN predictions to truth
animate_prediction(uw_NN, "uw", ğ’Ÿtest, test_file; legend_labels=["NN(u,v,T)", "truth"], filename="uw_NN_$(test_file)", directory=output_gif_directory)
animate_prediction(vw_NN, "vw", ğ’Ÿtest, test_file; legend_labels=["NN(u,v,T)", "truth"], filename="vw_NN_$(test_file)", directory=output_gif_directory)
animate_prediction(wT_NN, "wT", ğ’Ÿtest, test_file; legend_labels=["NN(u,v,T)", "truth"], filename="wT_NN_$(test_file)", directory=output_gif_directory)

## Gaussian Process Regression

# A. Find the kernel that minimizes the prediction error on the training data
# * Sweeps over length-scale hyperparameter value in logÎ³_range
# * Sweeps over covariance functions
logÎ³_range=-1.0:0.5:1.0 # sweep over length-scale hyperparameter
# uncomment the next three lines to try this but just for testing the GPR use the basic get_kernel stuff below
# uw_kernel = best_kernel(ğ’Ÿtrain.uw, logÎ³_range=logÎ³_range)
# vw_kernel = best_kernel(ğ’Ÿtrain.uw, logÎ³_range=logÎ³_range)
# wT_kernel = best_kernel(ğ’Ÿtrain.uw, logÎ³_range=logÎ³_range)

# OR set the kernel manually here (to save a bunch of time):
uw_kernel = get_kernel(1,0.1,0.0,euclidean_distance)
vw_kernel = get_kernel(1,0.1,0.0,euclidean_distance)
wT_kernel = get_kernel(1,0.1,0.0,euclidean_distance)

# Trained GP models
uw_GP_model = gp_model(ğ’Ÿtrain.uw, uw_kernel)
vw_GP_model = gp_model(ğ’Ÿtrain.vw, vw_kernel)
wT_GP_model = gp_model(ğ’Ÿtrain.wT, wT_kernel)

# GP predictions on test data
uw_GP = predict(ğ’Ÿtest.uw, uw_GP_model)
vw_GP = predict(ğ’Ÿtest.vw, vw_GP_model)
wT_GP = predict(ğ’Ÿtest.wT, wT_GP_model)

mse(x::Tuple{Array{Float64,2}, Array{Float64,2}}) = Flux.mse(x[1], x[2])
mse(uw_GP)
mse(vw_GP)
mse(wT_GP)

# Compare GP predictions to truth
animate_prediction(uw_GP, "uw", ğ’Ÿtest, test_file; legend_labels=["GP(u,v,T)", "truth"], filename="uw_GP_$(test_file)", directory=output_gif_directory)
animate_prediction(vw_GP, "vw", ğ’Ÿtest, test_file; legend_labels=["GP(u,v,T)", "truth"], filename="vw_GP_$(test_file)", directory=output_gif_directory)
animate_prediction(wT_GP, "wT", ğ’Ÿtest, test_file; legend_labels=["GP(u,v,T)", "truth"], filename="wT_GP_$(test_file)", directory=output_gif_directory)

## KPP Parameterization (no training)

# les = read_les_output(test_file)
parameters = KPP.Parameters() # default parameters
KPP_model = closure_kpp_full_evolution(parameters, ğ’Ÿtest.T.coarse[:,1], Î”t, les)
predictions = KPP_model()
T_KPP = (predictions, ğ’Ÿtest.T.coarse)
mse(T_KPP)
animate_prediction(T_KPP, "T", ğ’Ÿtest, test_file; legend_labels=["KPP(T)", "truth"], filename="T_KPP_$(test_file)", directory=output_gif_directory)

## TKE Parameterization (no training; use default parameters)

# les = read_les_output(test_file)
parameters = TKEMassFlux.TKEParameters() # default parameters
TKE_model = closure_tke_full_evolution(parameters, ğ’Ÿtest.T.coarse[:,1], Î”t, les)()
predictions = TKE_model()
T_TKE = (predictions, ğ’Ÿtest.T.coarse)
mse(T_TKE)
animate_prediction(T_TKE, "T", ğ’Ÿtest, test_file; legend_labels=["TKE(T)", "truth"], filename="T_TKE_$(test_file)", directory=output_gif_directory)

## Solving the PDEs using the predictions from NN or GP models

# central derivative as gradient approximator, periodic boundary conditions
function central_difference(input, z)
    Î” = z[2] - z[1]
    output = similar(input)
    vals = @view output[2:length(output)-1]
    vals .= (@view(input[3:end]) .- @view(input[1:end-2])) ./ (2Î”)
    # output[1] = (input[2] - input[end]) / (2Î”)
    # output[end] = (input[1] - input[end-1])/(2Î”)
    output[1] = 0
    output[end] = 0
    return output
end

# interpolation from face centered values to cell centered values
function face_to_cell(input)
    output = similar(input, length(input)-1)
    output .= (@view(input[1:end-1]) .+ @view(input[2:end]) ) ./ 2
    return output
end

# splicing data to train the NN
function time_window(t, uvT, stopindex)
    if stopindex < length(t)
        return (t[1:stopindex], uvT[:,1:stopindex])
    else
        @info "stop index larger than length of t"
    end
end

function cell_to_cell_derivative(D, data)
    face_data = D * data
    cell_data = 0.5 .* (@view(face_data[1:end-1]) .+ @view(face_data[2:end]))
    return cell_data
end

f = les.fá¶¿
zF_coarse = ğ’Ÿtest.uw.z
zC_coarse = ğ’Ÿtest.u.z
H = abs(zF_coarse[end] - zF_coarse[1])
Ï„ = abs(ğ’Ÿtest.t[end] - ğ’Ÿtest.t[1])
Nz = length(zC_coarse)
uvT_scaled = ğ’Ÿtest.uvT_scaled
tspan_train = (0.0, t[2])
uvTâ‚€ = uvT_scaled[:,1]

get_Î¼_Ïƒ(name) = (ğ’Ÿtest.scalings[name].Î¼, ğ’Ÿtest.scalings[name].Ïƒ)
Î¼_u, Ïƒ_u = get_Î¼_Ïƒ("u")
Î¼_v, Ïƒ_v = get_Î¼_Ïƒ("v")
Î¼_T, Ïƒ_T = get_Î¼_Ïƒ("T")
Î¼_uw, Ïƒ_uw = get_Î¼_Ïƒ("uw")
Î¼_vw, Ïƒ_vw = get_Î¼_Ïƒ("vw")
Î¼_wT, Ïƒ_wT = get_Î¼_Ïƒ("wT")

uw_weights, re_uw = Flux.destructure(uw_NN_model)
vw_weights, re_vw = Flux.destructure(vw_NN_model)
wT_weights, re_wT = Flux.destructure(wT_NN_model)

p_nondimensional = Float32.(cat(f, Ï„, H, Nz, Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T, Ïƒ_uw, Ïƒ_vw, Ïƒ_wT, uw_weights, vw_weights, wT_weights, dims=1))

function NDE_nondimensional!(dx, x, p, t)
    f, Ï„, H, Nz, Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T, Ïƒ_uw, Ïƒ_vw, Ïƒ_wT = p[1:12]
    Nz = 32
    uw_weights = p[13:21740]
    vw_weights = p[21741:43468]
    wT_weights = p[43469:end]
    uw_NN_model = re_uw(uw_weights)
    vw_NN_model = re_vw(vw_weights)
    wT_NN_model = re_wT(wT_weights)
    A = - Ï„ / H
    B = f * Ï„
    D_face = Dá¶ (Nz, 1/Nz)
    D_cell = Dá¶œ(Nz, 1/Nz)
    u = x[1:Nz]
    v = x[Nz+1:2*Nz]
    T = x[2*Nz+1:end]
    dx[1:Nz] .= A .* Ïƒ_uw ./ Ïƒ_u .* cell_to_cell_derivative(D_face, uw_NN_model(x)) .+ B ./ Ïƒ_u .* (Ïƒ_v .* v .+ Î¼_v) #nondimensional gradient
    dx[Nz+1:2*Nz] .= A .* Ïƒ_vw ./ Ïƒ_v .* cell_to_cell_derivative(D_face, vw_NN_model(x)) .- B ./ Ïƒ_v .* (Ïƒ_u .* u .+ Î¼_u)
    dx[2*Nz+1:end] .= A .* Ïƒ_wT ./ Ïƒ_T .* (D_cell * wT_NN_model(x))
end

t_train, uvT_train = time_window(ğ’Ÿtest.t, ğ’Ÿtest.uvT_scaled, 10)
t_train = Float32.(t_train ./ Ï„)
# t_train, uvT_train = time_window(t, uvT_scaled, 100)
prob = ODEProblem(NDE_nondimensional!, uvTâ‚€, (t_train[1], t_train[end]), p_nondimensional, saveat=t_train) # divide Ï„ needs to be changed

# tpoint = 1000
sol = solve(prob)
# plot(sol[:,tpoint][33:64], zC_coarse)
# plot!(uvT_scaled[:,tpoint][33:64], zC_coarse)

function loss_NDE_NN()
    p = Float32.(cat(f, Ï„, H, Nz, Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T, Ïƒ_uw, Ïƒ_vw, Ïƒ_wT, uw_weights, vw_weights, wT_weights, dims=1))
    # _prob = remake(prob, p=p)
    _sol = Array(solve(prob, ROCK4(), p=p, reltol=1e-3, sense=InterpolatingAdjoint(autojacvec=ZygoteVJP())))
    loss = Flux.mse(_sol, uvT_train)
    return loss
end

function cb()
    p = cat(f, Ï„, H, Nz, Î¼_u, Î¼_v, Ïƒ_u, Ïƒ_v, Ïƒ_T, Ïƒ_uw, Ïƒ_vw, Ïƒ_wT, uw_weights, vw_weights, wT_weights, dims=1)
    # _prob = remake(prob, p=p)
    _sol = Array(solve(prob, ROCK4(), p=p, sense=InterpolatingAdjoint(autojacvec=ZygoteVJP())))
    loss = Flux.mse(_sol, uvT_train)
    @info loss
    return _sol
end

Flux.train!(loss_NDE_NN, Flux.params(uw_weights, vw_weights, wT_weights), Iterators.repeated((), 100), ADAM(0.01), cb=Flux.throttle(cb, 2))

tpoint = 100
_sol = cb()
plot(_sol[:,tpoint][33:64], zC_coarse, label="NDE")
plot!(uvT_scaled[:,tpoint][33:64], zC_coarse, label="truth")
plot(_sol[:,tpoint][1:32], zC_coarse, label="NDE")
plot!(uvT_scaled[:,tpoint][1:32], zC_coarse, label="truth")
plot(_sol[:,tpoint][65:end], zC_coarse, label="NDE", legend=:topleft)
plot!(uvT_scaled[:,tpoint][65:end], zC_coarse, label="truth")
